{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../data/\"\n",
    "train = pd.read_parquet(path+\"train.parquet\")\n",
    "\n",
    "train, test = train_test_split(train, test_size=0.2, random_state=1)\n",
    "eval, test = train_test_split(test, test_size=0.5, random_state=1)\n",
    "\n",
    "sub = pd.read_csv(path+\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38751, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>623e2aa50f13aece7fb1c60cf555d8c7d290692f679655...</td>\n",
       "      <td>Phân tích kết quả sản xuất (KQSX) về chất lượn...</td>\n",
       "      <td>Để phân tích kết quả sản xuất (KQSX) về chất l...</td>\n",
       "      <td>Phân tích kết quả sản xuất (KQSX) về chất lượn...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>yi-lightning</td>\n",
       "      <td>internlm2_5-20b-chat</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34859</th>\n",
       "      <td>b87079eef09873032f653314cfddd05e7bf77e4e6d0449...</td>\n",
       "      <td>Write a sample of Old Uyghur</td>\n",
       "      <td>Providing a truly representative sample of Old...</td>\n",
       "      <td>I apologize, but I cannot generate an authenti...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  ...    language\n",
       "18632  623e2aa50f13aece7fb1c60cf555d8c7d290692f679655...  ...  Vietnamese\n",
       "34859  b87079eef09873032f653314cfddd05e7bf77e4e6d0449...  ...     English\n",
       "\n",
       "[2 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{train.shape}\")\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/ya.pristalov/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "100%|██████████| 38751/38751 [00:01<00:00, 20317.58it/s]\n",
      "100%|██████████| 38751/38751 [00:05<00:00, 6673.76it/s]\n",
      "100%|██████████| 38751/38751 [00:05<00:00, 6689.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "def get_n_sents(line: str) -> int:\n",
    "    return len(sent_tokenize(line))\n",
    "\n",
    "def get_sents(line: str) -> int:\n",
    "    return sent_tokenize(line)\n",
    "\n",
    "prompt_sents = train['prompt'].progress_apply(get_sents)\n",
    "response_a_sents = train['response_a'].progress_apply(get_sents)\n",
    "response_b_sents = train['response_b'].progress_apply(get_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18014 34784 34776\n",
      "(87574,)\n",
      "1566154\n"
     ]
    }
   ],
   "source": [
    "N_SENTS_THRESHOLD = 1\n",
    "prompt_sents = prompt_sents[prompt_sents.apply(len) > N_SENTS_THRESHOLD]\n",
    "response_a_sents = response_a_sents[response_a_sents.apply(len) > N_SENTS_THRESHOLD]\n",
    "response_b_sents = response_b_sents[response_b_sents.apply(len) > N_SENTS_THRESHOLD]\n",
    "\n",
    "print(len(prompt_sents), len(response_a_sents), len(response_b_sents))\n",
    "\n",
    "sentences = pd.concat([prompt_sents, response_a_sents, response_b_sents])\n",
    "print(sentences.shape)\n",
    "\n",
    "plain_sentences = []\n",
    "def make_sents_plain(sents_list: list[str], plain_sentences: list[str]):\n",
    "    plain_sentences.extend(sents_list)\n",
    "sentences.apply(make_sents_plain, args=(plain_sentences,))\n",
    "print(len(plain_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['For this argument, consequentialism is like kinetic theory of gases.',\n",
       "  \"The point is not that it's wrong and doesn't work (where it should), but that it's not a relevant tool for many purposes.\",\n",
       "  1],\n",
       " [\"The point is not that it's wrong and doesn't work (where it should), but that it's not a relevant tool for many purposes.\",\n",
       "  'I started giving up on consequentialism when thinking about concepts of alignment like corrigibility and then membranes (respect for autonomy).',\n",
       "  1],\n",
       " ['I started giving up on consequentialism when thinking about concepts of alignment like corrigibility and then membranes (respect for autonomy).',\n",
       "  \"They could in principle be framed as particular preferences, but that doesn't apear to be a natural way of thinking about them, of formulating them more clearly.\",\n",
       "  1]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_positive_pairs(\n",
    "        raw_sentences  # : pd.Series[list[str]]\n",
    "    ) -> list[list[str]]:\n",
    "    positive_pairs = []\n",
    "\n",
    "    def extend_positive_pairs(sent_list: list[str], positive_pairs: list[list[str]]):\n",
    "        for i in range(len(sent_list) - 1):\n",
    "            positive_pairs.append([sent_list[i], sent_list[i + 1], 1])\n",
    "\n",
    "    raw_sentences.apply(extend_positive_pairs, args=(positive_pairs,))\n",
    "    return positive_pairs\n",
    "\n",
    "positive_pairs = build_positive_pairs(sentences)\n",
    "print(len(positive_pairs))\n",
    "positive_pairs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1566154"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_sentences.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 58449/1478580 [00:00<00:02, 584473.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478580/1478580 [00:02<00:00, 505089.12it/s]\n"
     ]
    }
   ],
   "source": [
    "negative_pairs = []\n",
    "choice_range_max = len(plain_sentences)\n",
    "n_negative_per_one_positive = 1\n",
    "\n",
    "for pair in tqdm(positive_pairs):\n",
    "    for _ in range(n_negative_per_one_positive):\n",
    "        negative_pairs.append(\n",
    "            [\n",
    "                pair[0], \n",
    "                plain_sentences[np.random.randint(0, choice_range_max)],\n",
    "                0\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['For this argument, consequentialism is like kinetic theory of gases.',\n",
       "  '2.',\n",
       "  0],\n",
       " [\"The point is not that it's wrong and doesn't work (where it should), but that it's not a relevant tool for many purposes.\",\n",
       "  'Questi file sono chiamati template files.',\n",
       "  0],\n",
       " ['I started giving up on consequentialism when thinking about concepts of alignment like corrigibility and then membranes (respect for autonomy).',\n",
       "  '**Smarty Cache Configuration**: Ensure that Smarty caching is properly configured.',\n",
       "  0],\n",
       " [\"They could in principle be framed as particular preferences, but that doesn't apear to be a natural way of thinking about them, of formulating them more clearly.\",\n",
       "  '86.',\n",
       "  0],\n",
       " ['Even in decision theory, with the aim of getting certain outcomes to pass, my current preferred ontology of simulation-structure of things points more towards convincing other computations to move the world in certain ways than towards anticipating their behavior before they decide what it should be themselves.',\n",
       "  'This typically includes a mix of theoretical learning, practical skills, critical thinking, and ethical development.',\n",
       "  0],\n",
       " ['It\\'s still a sort of \"consequentialism\", but the property of preferences being unchanging is not a centerpiece, and the updateless manipulation of everything else is more of a technical error (like two-boxing in ASP) than a methodology.',\n",
       "  '#### Responsibility for Operation\\n\\n- **Navigation and Safety**: The staff navigates the vessel and ensures the safety of customers.',\n",
       "  0],\n",
       " ['In human thinking, issues with consequentialism seem to be about losing sight of chasing the void.',\n",
       "  'She has two boxes, one with a faulty calendar (90% chance to display the correct date, 10% chance to display a random date from {Monday, Tuesday}).',\n",
       "  0],\n",
       " ['Reflectively endorsed hedonistic goals (in a broad sense, which could include enjoyment of achievement) are a bit of a dead end, denying the process of looking for different kinds of aims, sometimes cynical reveling in knowing the secrets of human nature.',\n",
       "  'Quá trình này bao gồm nhiều giai đoạn khác nhau, nhưng luôn phát triển liên tục.',\n",
       "  0],\n",
       " ['9.',\n",
       "  '**Check Permissions:** Query the database to see if the user already has read-only access on the tables.',\n",
       "  0],\n",
       " ['У чебурашки большие уши и волосатая грудь - рецесивные гены, локализованные в Х-хромосоме на расстоянии 20 морганид.',\n",
       "  \"Il existe de nombreuses ressources disponibles pour vous aider (centres d'emploi, associations, etc.).\",\n",
       "  0]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478580, 1478580)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_pairs), len(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>next</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAUX : Lors du dépistage du VIH par les tests ...</td>\n",
       "      <td>3.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What worked well?</td>\n",
       "      <td>What could you have done better?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* **Customer Segmentation and Profiling:** Gen...</td>\n",
       "      <td>- The Slaver's speech to the crowd is particul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luật này quy định về thủ tục, hồ sơ, thẩm quyề...</td>\n",
       "      <td>`using System;`: Dòng này khai báo sử dụng khô...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensure Reproducibility and Ethical Considerati...</td>\n",
       "      <td>8.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957155</th>\n",
       "      <td>### Prompt:\\nDiscuss the key differences and p...</td>\n",
       "      <td>Their work was physically demanding and often ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957156</th>\n",
       "      <td>知識渦** (Cerebral Vortex)\\n肥大化した脳を高速回転させ、周囲に強烈な空...</td>\n",
       "      <td>U.N. and O.A.S.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957157</th>\n",
       "      <td>Here are 10 (or more) to capture that bashful ...</td>\n",
       "      <td>final now = DateTime.now();\\n    const exitWar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957158</th>\n",
       "      <td>Астрид указала на полку с книгами о садоводстве.</td>\n",
       "      <td>**応用力（問3）**\\n   - **得点**: 8/10\\n   - **評価**: エ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957159</th>\n",
       "      <td>- **Ventilation**:\\n  - Shoes with poor ventil...</td>\n",
       "      <td>The war-weary Elector Counts suddenly took an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2957160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     start  ... label\n",
       "0        FAUX : Lors du dépistage du VIH par les tests ...  ...     0\n",
       "1                                        What worked well?  ...     1\n",
       "2        * **Customer Segmentation and Profiling:** Gen...  ...     0\n",
       "3        Luật này quy định về thủ tục, hồ sơ, thẩm quyề...  ...     0\n",
       "4        Ensure Reproducibility and Ethical Considerati...  ...     0\n",
       "...                                                    ...  ...   ...\n",
       "2957155  ### Prompt:\\nDiscuss the key differences and p...  ...     0\n",
       "2957156  知識渦** (Cerebral Vortex)\\n肥大化した脳を高速回転させ、周囲に強烈な空...  ...     0\n",
       "2957157  Here are 10 (or more) to capture that bashful ...  ...     0\n",
       "2957158   Астрид указала на полку с книгами о садоводстве.  ...     0\n",
       "2957159  - **Ventilation**:\\n  - Shoes with poor ventil...  ...     0\n",
       "\n",
       "[2957160 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pairs: pd.DataFrame = pd.concat([\n",
    "    pd.DataFrame(positive_pairs),\n",
    "    pd.DataFrame(negative_pairs),  \n",
    "])\n",
    "\n",
    "all_pairs.columns = ['start', 'next', 'label']\n",
    "dataset = all_pairs.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('nsp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
