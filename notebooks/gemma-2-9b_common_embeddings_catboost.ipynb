{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training notebook: https://www.kaggle.com/code/ravaghi/wsdm-cup-gemma-2-9b-4-bit-qlora-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:11:22.512000Z",
     "iopub.status.busy": "2025-03-15T09:11:22.511692Z",
     "iopub.status.idle": "2025-03-15T09:15:34.018316Z",
     "shell.execute_reply": "2025-03-15T09:15:34.017389Z",
     "shell.execute_reply.started": "2025-03-15T09:11:22.511961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install accelerate peft bitsandbytes transformers trl unsloth seaborn \n",
    "!pip install --upgrade 'optree>=0.13.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-15T09:15:34.020561Z",
     "iopub.status.busy": "2025-03-15T09:15:34.020266Z",
     "iopub.status.idle": "2025-03-15T09:15:57.620909Z",
     "shell.execute_reply": "2025-03-15T09:15:57.620037Z",
     "shell.execute_reply.started": "2025-03-15T09:15:34.020539Z"
    },
    "papermill": {
     "duration": 6.541306,
     "end_time": "2025-01-09T12:40:45.050324",
     "exception": false,
     "start_time": "2025-01-09T12:40:38.509018",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from timeit import default_timer as timer\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.special import logit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "import torch\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "gemma_2_9b_4bit_it_unsloth_transformers_default_1_path = kagglehub.model_download('leimeng46/gemma-2-9b-4bit-it-unsloth/Transformers/default/1')\n",
    "wsdm_cup_gemma_2_9b_4_bit_qlora_path = kagglehub.dataset_download('ravaghi/wsdm-cup-gemma-2-9b-4-bit-qlora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:15:57.622748Z",
     "iopub.status.busy": "2025-03-15T09:15:57.622138Z",
     "iopub.status.idle": "2025-03-15T09:15:57.627664Z",
     "shell.execute_reply": "2025-03-15T09:15:57.626717Z",
     "shell.execute_reply.started": "2025-03-15T09:15:57.622722Z"
    },
    "papermill": {
     "duration": 0.01474,
     "end_time": "2025-01-09T12:40:45.071185",
     "exception": false,
     "start_time": "2025-01-09T12:40:45.056445",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    train_path = '../data/train.parquet'\n",
    "    test_path = '../data/train.parquet'\n",
    "    sample_sub_path = '/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv'\n",
    "\n",
    "    data_path = '/kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora'\n",
    "\n",
    "    gemma_dir = gemma_2_9b_4bit_it_unsloth_transformers_default_1_path + \"/gemma-2-9b-it-4bit-unsloth_old\"\n",
    "    lora_dir = wsdm_cup_gemma_2_9b_4_bit_qlora_path + \"/gemma2-9b-4bit/gemma-2-9b-it-bnb-4bit-3072-8/checkpoint-2900\"\n",
    "    \n",
    "    max_length = 3072\n",
    "    batch_size = 4\n",
    "\n",
    "    target = 'winner'\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "\n",
    "    char_vectorizer_params = {\n",
    "        'analyzer': \"char\",\n",
    "        \"lowercase\": False,\n",
    "        \"max_df\": 0.605,\n",
    "        \"max_features\": 331,\n",
    "        \"min_df\": 0.075,\n",
    "        \"ngram_range\": (1, 3),\n",
    "        \"strip_accents\": \"unicode\"\n",
    "    }\n",
    "\n",
    "    word_vectorizer_params = {\n",
    "        \"analyzer\": \"word\",\n",
    "        \"lowercase\": True,\n",
    "        \"max_df\": 0.985,\n",
    "        \"max_features\": 769,\n",
    "        \"min_df\": 0.01,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"strip_accents\": \"unicode\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma-2 9b 4-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:15:57.628845Z",
     "iopub.status.busy": "2025-03-15T09:15:57.628541Z",
     "iopub.status.idle": "2025-03-15T09:15:58.692212Z",
     "shell.execute_reply": "2025-03-15T09:15:58.691537Z",
     "shell.execute_reply.started": "2025-03-15T09:15:57.628816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:15:58.693508Z",
     "iopub.status.busy": "2025-03-15T09:15:58.693132Z",
     "iopub.status.idle": "2025-03-15T09:16:01.377171Z",
     "shell.execute_reply": "2025-03-15T09:16:01.376522Z",
     "shell.execute_reply.started": "2025-03-15T09:15:58.693471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(CFG.test_path).fillna('')\n",
    "train, test = train_test_split(test, test_size=0.2, random_state=1)\n",
    "val, test = train_test_split(test, test_size=0.5, random_state=1)\n",
    "train = pd.concat((train, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:16:01.379907Z",
     "iopub.status.busy": "2025-03-15T09:16:01.379689Z",
     "iopub.status.idle": "2025-03-15T09:16:01.383354Z",
     "shell.execute_reply": "2025-03-15T09:16:01.382711Z",
     "shell.execute_reply.started": "2025-03-15T09:16:01.379890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if len(test) > 10_000:\n",
    "    time_limit = int(3600 * 12) \n",
    "else:\n",
    "    time_limit = int(3600 * 4.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:16:01.385207Z",
     "iopub.status.busy": "2025-03-15T09:16:01.384930Z",
     "iopub.status.idle": "2025-03-15T09:16:01.400860Z",
     "shell.execute_reply": "2025-03-15T09:16:01.400238Z",
     "shell.execute_reply.started": "2025-03-15T09:16:01.385186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, prompt, response_a, response_b, max_length=CFG.max_length):\n",
    "    prompt = [\"<prompt>: \" + t for t in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + t for t in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + t for t in response_b]\n",
    "    \n",
    "    texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "    tokenized = tokenizer(texts, max_length=max_length, truncation=True)\n",
    "    \n",
    "    return tokenized['input_ids'], tokenized['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ya.pristalov/.cache/kagglehub/models/leimeng46/gemma-2-9b-4bit-it-unsloth/Transformers/default/1/gemma-2-9b-it-4bit-unsloth_old'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.gemma_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:16:01.401869Z",
     "iopub.status.busy": "2025-03-15T09:16:01.401633Z",
     "iopub.status.idle": "2025-03-15T09:16:02.627574Z",
     "shell.execute_reply": "2025-03-15T09:16:02.626863Z",
     "shell.execute_reply.started": "2025-03-15T09:16:01.401850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = GemmaTokenizerFast.from_pretrained(CFG.gemma_dir)\n",
    "\n",
    "\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T09:16:02.628575Z",
     "iopub.status.busy": "2025-03-15T09:16:02.628322Z",
     "iopub.status.idle": "2025-03-15T09:16:19.550727Z",
     "shell.execute_reply": "2025-03-15T09:16:19.549835Z",
     "shell.execute_reply.started": "2025-03-15T09:16:02.628554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4844/4844 [00:01<00:00, 3290.47it/s]\n",
      "100%|██████████| 4844/4844 [00:02<00:00, 1687.36it/s]\n",
      "100%|██████████| 4844/4844 [00:02<00:00, 1660.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    test[col] = test[col].fillna('')\n",
    "    text_list = []\n",
    "    if col == \"prompt\":\n",
    "        max_no = 512\n",
    "        s_no = 255\n",
    "        e_no = -256\n",
    "    else:\n",
    "        max_no = 3072\n",
    "        s_no = 1535\n",
    "        e_no = -1536\n",
    "    for text in tqdm(test[col]):\n",
    "        encoded = tokenizer(text, return_offsets_mapping=True)\n",
    "        if len(encoded['input_ids']) > max_no:\n",
    "            start_idx, end_idx = encoded['offset_mapping'][s_no]\n",
    "            new_text = text[:end_idx]\n",
    "            start_idx, end_idx = encoded['offset_mapping'][e_no]\n",
    "            new_text = new_text + \"\\n(snip)\\n\" + text[start_idx:]\n",
    "            text = new_text\n",
    "        text_list.append(text)\n",
    "    test[col] = text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:16:19.552013Z",
     "iopub.status.busy": "2025-03-15T09:16:19.551688Z",
     "iopub.status.idle": "2025-03-15T09:16:30.723726Z",
     "shell.execute_reply": "2025-03-15T09:16:30.723056Z",
     "shell.execute_reply.started": "2025-03-15T09:16:19.551980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7419</th>\n",
       "      <td>271ba404fc25609b8ceb6f37c3375f278c42e2479514ea...</td>\n",
       "      <td>Улучшь сообщение: Добрый вечер! \\nЭто Алексей ...</td>\n",
       "      <td>Добрый вечер!\\n\\nМеня зовут Алексей Королев, я...</td>\n",
       "      <td>Добрый вечер!\\n\\nЯ, Алексей Королев, заместите...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>qwen-max-0919</td>\n",
       "      <td>c4ai-aya-expanse-32b</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39112</th>\n",
       "      <td>ce7be103ac8f040accc9b8ec421a6cbf78189c503671df...</td>\n",
       "      <td>i have a notification icon in my webpage. when...</td>\n",
       "      <td>Certainly! To implement a notification system ...</td>\n",
       "      <td>Here's a simple example of how you can achieve...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>qwen2.5-72b-instruct</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33946</th>\n",
       "      <td>b39725e0a7992eb0c5f34542f960727a4fd306741568fb...</td>\n",
       "      <td>I have a raspberry pi that is booted from USB....</td>\n",
       "      <td>**Hotplugging the SD Card on a Raspberry Pi**\\...</td>\n",
       "      <td>No, you generally **cannot** safely hotplug th...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>gemini-1.5-pro-exp-0827</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35392</th>\n",
       "      <td>bb33f84e8e85da9e41fa271f6210fdffba0400d725a04c...</td>\n",
       "      <td>Imagine video on YouTube \"Asking people what i...</td>\n",
       "      <td>Here are some imagined YouTube comments relati...</td>\n",
       "      <td>Here are some comments that might appear under...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10254</th>\n",
       "      <td>364c8146a6a236fbdfa34492dba10405a0e448d3062316...</td>\n",
       "      <td>generate a wine description</td>\n",
       "      <td>Please provide some context!  To generate a co...</td>\n",
       "      <td>**Wine Description:**\\n\\n**Name:** Sunset on t...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemini-1.5-flash-8b-001</td>\n",
       "      <td>llama-3.1-70b-instruct</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26506</th>\n",
       "      <td>8bd008cebcfd4a9e504f0dbca5a5664d412ca9b4c4045f...</td>\n",
       "      <td>\"La existencia de diferencias con respecto a c...</td>\n",
       "      <td>La presencia de variaciones en los espectros d...</td>\n",
       "      <td>La presencia de diferencias según el gas utili...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>198aa3635a6fc9f6a7d069e82cc9cddcbc783e3a0e83e8...</td>\n",
       "      <td>Thế nào là tham nhũng?\\n\\n    Tham nhũng là hà...</td>\n",
       "      <td>Theo Khoản 1, Điều 353 Bộ luật Hình sự năm 201...</td>\n",
       "      <td>**Câu 1: Thế nào là tham nhũng?**\\n\\n**Đáp án ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16686</th>\n",
       "      <td>584414c294899b255a9576ade65032610ca1937cffcad4...</td>\n",
       "      <td>Which number is greater: 9.11 or 9.9?\\nIs 9.11...</td>\n",
       "      <td>Let's compare the two numbers step by step:\\n\\...</td>\n",
       "      <td>9.11 is greater than 9.9.</td>\n",
       "      <td>model_a</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>deepseek-v2.5</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28451</th>\n",
       "      <td>95fb0a8dabf14619a9564334dc390cbf170a0e09905086...</td>\n",
       "      <td>```\\nto order the special call commission for ...</td>\n",
       "      <td>This is a transcript of a Kentucky Fish and Wi...</td>\n",
       "      <td>This transcript details a special call commiss...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>gemini-1.5-flash-8b-001</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28115</th>\n",
       "      <td>94398d7223a8eee98c30692811b107563e082cb8936834...</td>\n",
       "      <td>Virgo daily horoscope for today. One paragraph...</td>\n",
       "      <td>## Virgo Daily Horoscope\\n\\n**Health and Welln...</td>\n",
       "      <td>**Health &amp; Wellness:** Stay active today to bo...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>reka-flash-20240904</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4844 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  \\\n",
       "7419   271ba404fc25609b8ceb6f37c3375f278c42e2479514ea...   \n",
       "39112  ce7be103ac8f040accc9b8ec421a6cbf78189c503671df...   \n",
       "33946  b39725e0a7992eb0c5f34542f960727a4fd306741568fb...   \n",
       "35392  bb33f84e8e85da9e41fa271f6210fdffba0400d725a04c...   \n",
       "10254  364c8146a6a236fbdfa34492dba10405a0e448d3062316...   \n",
       "...                                                  ...   \n",
       "26506  8bd008cebcfd4a9e504f0dbca5a5664d412ca9b4c4045f...   \n",
       "4869   198aa3635a6fc9f6a7d069e82cc9cddcbc783e3a0e83e8...   \n",
       "16686  584414c294899b255a9576ade65032610ca1937cffcad4...   \n",
       "28451  95fb0a8dabf14619a9564334dc390cbf170a0e09905086...   \n",
       "28115  94398d7223a8eee98c30692811b107563e082cb8936834...   \n",
       "\n",
       "                                                  prompt  \\\n",
       "7419   Улучшь сообщение: Добрый вечер! \\nЭто Алексей ...   \n",
       "39112  i have a notification icon in my webpage. when...   \n",
       "33946  I have a raspberry pi that is booted from USB....   \n",
       "35392  Imagine video on YouTube \"Asking people what i...   \n",
       "10254                        generate a wine description   \n",
       "...                                                  ...   \n",
       "26506  \"La existencia de diferencias con respecto a c...   \n",
       "4869   Thế nào là tham nhũng?\\n\\n    Tham nhũng là hà...   \n",
       "16686  Which number is greater: 9.11 or 9.9?\\nIs 9.11...   \n",
       "28451  ```\\nto order the special call commission for ...   \n",
       "28115  Virgo daily horoscope for today. One paragraph...   \n",
       "\n",
       "                                              response_a  \\\n",
       "7419   Добрый вечер!\\n\\nМеня зовут Алексей Королев, я...   \n",
       "39112  Certainly! To implement a notification system ...   \n",
       "33946  **Hotplugging the SD Card on a Raspberry Pi**\\...   \n",
       "35392  Here are some imagined YouTube comments relati...   \n",
       "10254  Please provide some context!  To generate a co...   \n",
       "...                                                  ...   \n",
       "26506  La presencia de variaciones en los espectros d...   \n",
       "4869   Theo Khoản 1, Điều 353 Bộ luật Hình sự năm 201...   \n",
       "16686  Let's compare the two numbers step by step:\\n\\...   \n",
       "28451  This is a transcript of a Kentucky Fish and Wi...   \n",
       "28115  ## Virgo Daily Horoscope\\n\\n**Health and Welln...   \n",
       "\n",
       "                                              response_b   winner  \\\n",
       "7419   Добрый вечер!\\n\\nЯ, Алексей Королев, заместите...  model_b   \n",
       "39112  Here's a simple example of how you can achieve...  model_b   \n",
       "33946  No, you generally **cannot** safely hotplug th...  model_a   \n",
       "35392  Here are some comments that might appear under...  model_a   \n",
       "10254  **Wine Description:**\\n\\n**Name:** Sunset on t...  model_b   \n",
       "...                                                  ...      ...   \n",
       "26506  La presencia de diferencias según el gas utili...  model_a   \n",
       "4869   **Câu 1: Thế nào là tham nhũng?**\\n\\n**Đáp án ...  model_b   \n",
       "16686                          9.11 is greater than 9.9.  model_a   \n",
       "28451  This transcript details a special call commiss...  model_b   \n",
       "28115  **Health & Wellness:** Stay active today to bo...  model_a   \n",
       "\n",
       "                       model_a                       model_b    language  \n",
       "7419             qwen-max-0919          c4ai-aya-expanse-32b     Russian  \n",
       "39112     qwen2.5-72b-instruct  llama-3.1-405b-instruct-bf16     English  \n",
       "33946    llama-3.1-8b-instruct       gemini-1.5-pro-exp-0827     English  \n",
       "35392     gemini-1.5-flash-002                gemma-2-27b-it     English  \n",
       "10254  gemini-1.5-flash-8b-001        llama-3.1-70b-instruct     English  \n",
       "...                        ...                           ...         ...  \n",
       "26506       gpt-4-1106-preview             gpt-4o-2024-08-06     Spanish  \n",
       "4869    claude-3-opus-20240229                       o1-mini  Vietnamese  \n",
       "16686        grok-2-2024-08-13                 deepseek-v2.5     English  \n",
       "28451       gemini-1.5-pro-002       gemini-1.5-flash-8b-001     English  \n",
       "28115           gemma-2-27b-it           reka-flash-20240904     English  \n",
       "\n",
       "[4844 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ya.pristalov/.cache/kagglehub/models/leimeng46/gemma-2-9b-4bit-it-unsloth/Transformers/default/1/gemma-2-9b-it-4bit-unsloth_old'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.gemma_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T09:16:30.724808Z",
     "iopub.status.busy": "2025-03-15T09:16:30.724522Z",
     "iopub.status.idle": "2025-03-15T09:17:50.425626Z",
     "shell.execute_reply": "2025-03-15T09:17:50.424907Z",
     "shell.execute_reply.started": "2025-03-15T09:16:30.724780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /home/ya.pristalov/.cache/kagglehub/models/leimeng46/gemma-2-9b-4bit-it-unsloth/Transformers/default/1/gemma-2-9b-it-4bit-unsloth_old and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    CFG.gemma_dir,\n",
    "    device_map=torch.device(\"cuda\"),\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:17:50.426722Z",
     "iopub.status.busy": "2025-03-15T09:17:50.426387Z",
     "iopub.status.idle": "2025-03-15T09:17:51.832785Z",
     "shell.execute_reply": "2025-03-15T09:17:51.832022Z",
     "shell.execute_reply.started": "2025-03-15T09:17:50.426689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, CFG.lora_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T09:17:51.833923Z",
     "iopub.status.busy": "2025-03-15T09:17:51.833681Z",
     "iopub.status.idle": "2025-03-15T09:17:51.855998Z",
     "shell.execute_reply": "2025-03-15T09:17:51.855271Z",
     "shell.execute_reply.started": "2025-03-15T09:17:51.833902Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "model.base_model.model.score = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:17:51.856976Z",
     "iopub.status.busy": "2025-03-15T09:17:51.856732Z",
     "iopub.status.idle": "2025-03-15T09:17:51.877352Z",
     "shell.execute_reply": "2025-03-15T09:17:51.876768Z",
     "shell.execute_reply.started": "2025-03-15T09:17:51.856957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size, max_length=CFG.max_length):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(df), batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))\n",
    "        \n",
    "        embeddings = outputs.logits.cpu()\n",
    "        \n",
    "        all_embeddings.extend(embeddings.tolist())\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:17:51.878351Z",
     "iopub.status.busy": "2025-03-15T09:17:51.878167Z",
     "iopub.status.idle": "2025-03-15T09:17:51.901070Z",
     "shell.execute_reply": "2025-03-15T09:17:51.900250Z",
     "shell.execute_reply.started": "2025-03-15T09:17:51.878335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "global_timer = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:17:51.902023Z",
     "iopub.status.busy": "2025-03-15T09:17:51.901803Z",
     "iopub.status.idle": "2025-03-15T09:17:51.931664Z",
     "shell.execute_reply": "2025-03-15T09:17:51.931022Z",
     "shell.execute_reply.started": "2025-03-15T09:17:51.902004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['index'] = np.arange(len(data), dtype=np.int32)\n",
    "data = data.sort_values(\"length\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>length</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79c362d0af7595cb69e665027d591df7ab83fe2d7dd34e...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 3893, 105821, 1982, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3072</td>\n",
       "      <td>3881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a83127929a103f8e0f35928e5902da56c2307c032378dd...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 206468, 3901, 190158...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3072</td>\n",
       "      <td>4208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49b5e589b60986b9088ab224965e0a9d0fc4a228484d7d...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 1004, 68574, 1454, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3072</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159fa657ef6484164d6253ad7b4a90e5de752213032bc0...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 182483, 6520, 12788,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3072</td>\n",
       "      <td>2216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4242d5a354ccda2f1da52cc889ff5908578432aff732a...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 7717, 11809, 42765, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3072</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>1cb8843f3e3352e005a362da220956fadf1d8bdfa46c52...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 5823, 131345, 2218, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>37</td>\n",
       "      <td>3814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>944a871333310cc97c688233b45c883837404577e44ac7...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 3337, 1297, 235248, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>2161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>b63122dabc0457a9c5f75541790f8627ba39b70c769229...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 123781, 109, 235322,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>1e2833f1fc663fe31efc6da3fd5626c5602d94db6e7ba2...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 3233, 109, 235322, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>35</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>71ec6a6d49029191fe376876d3ef371634b8f1a6550093...</td>\n",
       "      <td>[2, 235322, 39038, 78880, 5651, 1931, 664, 215...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>29</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4844 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     79c362d0af7595cb69e665027d591df7ab83fe2d7dd34e...   \n",
       "1     a83127929a103f8e0f35928e5902da56c2307c032378dd...   \n",
       "2     49b5e589b60986b9088ab224965e0a9d0fc4a228484d7d...   \n",
       "3     159fa657ef6484164d6253ad7b4a90e5de752213032bc0...   \n",
       "4     e4242d5a354ccda2f1da52cc889ff5908578432aff732a...   \n",
       "...                                                 ...   \n",
       "4839  1cb8843f3e3352e005a362da220956fadf1d8bdfa46c52...   \n",
       "4840  944a871333310cc97c688233b45c883837404577e44ac7...   \n",
       "4841  b63122dabc0457a9c5f75541790f8627ba39b70c769229...   \n",
       "4842  1e2833f1fc663fe31efc6da3fd5626c5602d94db6e7ba2...   \n",
       "4843  71ec6a6d49029191fe376876d3ef371634b8f1a6550093...   \n",
       "\n",
       "                                              input_ids  \\\n",
       "0     [2, 235322, 39038, 78880, 3893, 105821, 1982, ...   \n",
       "1     [2, 235322, 39038, 78880, 206468, 3901, 190158...   \n",
       "2     [2, 235322, 39038, 78880, 1004, 68574, 1454, 3...   \n",
       "3     [2, 235322, 39038, 78880, 182483, 6520, 12788,...   \n",
       "4     [2, 235322, 39038, 78880, 7717, 11809, 42765, ...   \n",
       "...                                                 ...   \n",
       "4839  [2, 235322, 39038, 78880, 5823, 131345, 2218, ...   \n",
       "4840  [2, 235322, 39038, 78880, 3337, 1297, 235248, ...   \n",
       "4841  [2, 235322, 39038, 78880, 123781, 109, 235322,...   \n",
       "4842  [2, 235322, 39038, 78880, 3233, 109, 235322, 4...   \n",
       "4843  [2, 235322, 39038, 78880, 5651, 1931, 664, 215...   \n",
       "\n",
       "                                         attention_mask  length  index  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    3072   3881  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    3072   4208  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    3072   2184  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    3072   2216  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    3072   2224  \n",
       "...                                                 ...     ...    ...  \n",
       "4839  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      37   3814  \n",
       "4840  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      36   2161  \n",
       "4841  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      36   3490  \n",
       "4842  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      35    808  \n",
       "4843  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      29    897  \n",
       "\n",
       "[4844 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1211/1211 [18:30<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = inference(\n",
    "    data,\n",
    "    model, \n",
    "    torch.device('cuda'),\n",
    "    CFG.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(embeddings)\n",
    "eval_df['id'] = data['id']\n",
    "\n",
    "eval_df = eval_df.merge(test[['id', 'winner']], on='id').drop(columns=['id'])\n",
    "\n",
    "train_eval_X, test_eval_X, train_eval_y, test_eval_y = train_test_split(eval_df.iloc[:, :-1], eval_df.iloc[:, -1], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.039428\n",
      "0:\tlearn: 0.6787779\ttest: 0.6696945\tbest: 0.6696945 (0)\ttotal: 4.59ms\tremaining: 4.59s\n",
      "100:\tlearn: 0.7369942\ttest: 0.7080925\tbest: 0.7089182 (97)\ttotal: 299ms\tremaining: 2.66s\n",
      "200:\tlearn: 0.7456647\ttest: 0.7085054\tbest: 0.7113955 (118)\ttotal: 603ms\tremaining: 2.4s\n",
      "300:\tlearn: 0.7551610\ttest: 0.7089182\tbest: 0.7113955 (118)\ttotal: 892ms\tremaining: 2.07s\n",
      "400:\tlearn: 0.7630058\ttest: 0.7105698\tbest: 0.7113955 (118)\ttotal: 1.17s\tremaining: 1.75s\n",
      "500:\tlearn: 0.7696119\ttest: 0.7101569\tbest: 0.7113955 (118)\ttotal: 1.49s\tremaining: 1.48s\n",
      "600:\tlearn: 0.7762180\ttest: 0.7126342\tbest: 0.7142857 (581)\ttotal: 1.85s\tremaining: 1.23s\n",
      "700:\tlearn: 0.7824112\ttest: 0.7138728\tbest: 0.7163501 (675)\ttotal: 2.22s\tremaining: 949ms\n",
      "800:\tlearn: 0.7910818\ttest: 0.7118084\tbest: 0.7163501 (675)\ttotal: 2.6s\tremaining: 646ms\n",
      "900:\tlearn: 0.7960363\ttest: 0.7118084\tbest: 0.7163501 (675)\ttotal: 2.98s\tremaining: 328ms\n",
      "999:\tlearn: 0.8047069\ttest: 0.7118084\tbest: 0.7163501 (675)\ttotal: 3.36s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7163501239\n",
      "bestIteration = 675\n",
      "\n",
      "Shrink model to first 676 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5440fbf0d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostClassifier(verbose=100, eval_metric='Accuracy', depth=1)\n",
    "\n",
    "clf.fit(train_eval_X, train_eval_y, eval_set=(test_eval_X, test_eval_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "datasetId": 6447806,
     "sourceId": 10601275,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 193770,
     "modelInstanceId": 171453,
     "sourceId": 200971,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3488.60841,
   "end_time": "2025-01-09T13:38:44.688186",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-09T12:40:36.079776",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
