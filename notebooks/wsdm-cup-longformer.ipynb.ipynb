{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":10601275,"sourceType":"datasetVersion","datasetId":6447806}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1687.537804,"end_time":"2025-01-14T09:56:43.440349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-14T09:28:35.902545","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0413a15497fb46208605c5c57267b8c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"051418f578d34d5dba2dd359d1109880":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0566ee288f5c42d987e238c6bbbeb030":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_dfab0d4df9684dffaeb90380707921e6","max":17525357,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f13215505b5e436ba039de631320b671","tabbable":null,"tooltip":null,"value":17525357}},"07487c7811fb45c18ff93a63abdec100":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a90b39003c34272b7da8d9d27847801":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a945edce7ca47cba745556b5ce445b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_6a55c91aeefa4c8098b4c6bdeaf3272c","max":80,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82a79514d4cc439abb4df14560d5cd36","tabbable":null,"tooltip":null,"value":80}},"0f2e7ed1ac0f4931811e9d8df040901e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0fb98eaf749c465b9064fcfa59cd6bb3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ef87ecaadb45a6a4578de95bc1f6aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6cac631d073f4985932d28e29238a972","placeholder":"​","style":"IPY_MODEL_2f8430b3218a4072b590f9884fc8a3c1","tabbable":null,"tooltip":null,"value":" 47.0k/47.0k [00:00&lt;00:00, 4.26MB/s]"}},"170fdc6e77ce41639028d5869b5821f3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ac6f172f02b47dabf8e274094591259":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd7a755925f7436681fff8b21664efd2","IPY_MODEL_0566ee288f5c42d987e238c6bbbeb030","IPY_MODEL_bc40890548b440d7a57cc74c5ecaada6"],"layout":"IPY_MODEL_ae15586675d9490099f2fc9de55b0bd9","tabbable":null,"tooltip":null}},"1bf8897275cc4b19b4e3f90092c64b7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24144c38d0574fbf96067e91240ac490":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5e9847b85804123a9de68295ab93ff9","IPY_MODEL_83af5b0873d94c6ba61a62cea77de792","IPY_MODEL_35f8428fea174836a0769b77e950f830"],"layout":"IPY_MODEL_3be549f5a58f4f78b5088a063deeaae2","tabbable":null,"tooltip":null}},"24e5091b6b59499ab5e01101dd58a40c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d5a53f6ac1498f97bb4962075bade0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c3dc8995f14433986d0cb24b6d93bae","IPY_MODEL_b982186c460242888653a74546793c62","IPY_MODEL_c9375635b68147729a7b2cf82f4df4be"],"layout":"IPY_MODEL_db33d80dd295427ab4ebe0915b2ec4ac","tabbable":null,"tooltip":null}},"2c43e516b2264a5bb610d776e4b837cf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ee549ef971047dc9bdb0d295231568a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f8430b3218a4072b590f9884fc8a3c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"337463f868094d81bc2b4fb59f6dc723":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0fb98eaf749c465b9064fcfa59cd6bb3","placeholder":"​","style":"IPY_MODEL_b822667faaa74c6ab01c395748c0d47d","tabbable":null,"tooltip":null,"value":"tokenizer.model: 100%"}},"35f8428fea174836a0769b77e950f830":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_efb3db409e384fa8be50a629696c13ad","placeholder":"​","style":"IPY_MODEL_69e7a41e342a40bdb1de1a591b57c64e","tabbable":null,"tooltip":null,"value":" 20/20 [00:00&lt;00:00, 448.48 examples/s]"}},"3a39e348e2f24e0dbe53cba104541ee4":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3be549f5a58f4f78b5088a063deeaae2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da49f6fd5da4bfb9ff78836f794e703":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3f37d2e527124376938c14326b79b4e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_adc080fd04e64214bb4fc228e79610ca","max":6130708068,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d150968782ef4535b7b433f9288d6b27","tabbable":null,"tooltip":null,"value":6130708068}},"468871e2c2074b83bc87e93adaeb87a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8f85824a9ce4b13a47c99ca2eec1b63","IPY_MODEL_afcd0fcba8b34ff68c6392fea7505756","IPY_MODEL_6afd42b7cfc24f2db97812cf0807fa6a"],"layout":"IPY_MODEL_3a39e348e2f24e0dbe53cba104541ee4","tabbable":null,"tooltip":null}},"494ad401c8c04f7780d3fdcf28632f69":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a27cd4f26154aea91ab5be4ca458f87":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ac199f5d688449f8259b15177201b13":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_65331a48752945fbbb370e0c0bd8e1a6","max":47022,"min":0,"orientation":"horizontal","style":"IPY_MODEL_748c20d82cd34ac3b731fac2511a1c33","tabbable":null,"tooltip":null,"value":47022}},"4b9c54644a7a4b6ab2cdaaa114fa9fe8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_337463f868094d81bc2b4fb59f6dc723","IPY_MODEL_7c1aada2d87948809f7d8b13bef557e8","IPY_MODEL_5df401d89f5944e28957e4aea7a331fb"],"layout":"IPY_MODEL_58924575ecf64cb885447ce4bcd41949","tabbable":null,"tooltip":null}},"4da0132b663d4cc3b604d246e2c2061e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52caf612425a43c6b546381726d4ffdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"58924575ecf64cb885447ce4bcd41949":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5df401d89f5944e28957e4aea7a331fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bbd6e0469beb47bc81c1d50093750366","placeholder":"​","style":"IPY_MODEL_d6421c66391e4114885675b48c2bfb83","tabbable":null,"tooltip":null,"value":" 4.24M/4.24M [00:00&lt;00:00, 41.4MB/s]"}},"5f5a966543e34b8584846bf6561635b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_654ae003398d451eb7d45e119b90d9d0","placeholder":"​","style":"IPY_MODEL_52caf612425a43c6b546381726d4ffdc","tabbable":null,"tooltip":null,"value":" 80/80 [00:00&lt;00:00, 292.30 examples/s]"}},"5f8b3662480f45ffb7ad6bb7a36ca378":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64cb32030ade4d21b675b5a4d28b7368":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65331a48752945fbbb370e0c0bd8e1a6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"654ae003398d451eb7d45e119b90d9d0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65a015ea58b248049139e4c46f47adf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"663e676afaa1484a8e142e7b28c01bab":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69e7a41e342a40bdb1de1a591b57c64e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6a55c91aeefa4c8098b4c6bdeaf3272c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6afd42b7cfc24f2db97812cf0807fa6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a79039f6fb864b72af7f43b25c3a9fb5","placeholder":"​","style":"IPY_MODEL_3da49f6fd5da4bfb9ff78836f794e703","tabbable":null,"tooltip":null,"value":" 1.41k/1.41k [00:00&lt;00:00, 148kB/s]"}},"6c3dc8995f14433986d0cb24b6d93bae":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2ee549ef971047dc9bdb0d295231568a","placeholder":"​","style":"IPY_MODEL_ca776aa684d34788ae9b58fbb0295d62","tabbable":null,"tooltip":null,"value":"special_tokens_map.json: 100%"}},"6cac631d073f4985932d28e29238a972":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dad674ae6014198b9825dca9c005214":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748c20d82cd34ac3b731fac2511a1c33":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7aa9071078434b0dbd90a46ea1696ac4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c2549c749394bc5b38f089948fb7e9e","IPY_MODEL_3f37d2e527124376938c14326b79b4e7","IPY_MODEL_f5d2db26e61b468b9864cad115489369"],"layout":"IPY_MODEL_ba9518850c7f4c0fb18cce654abd3458","tabbable":null,"tooltip":null}},"7c1aada2d87948809f7d8b13bef557e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e667f0c76d7f4bbe96de8ccaa0fc11de","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4da0132b663d4cc3b604d246e2c2061e","tabbable":null,"tooltip":null,"value":4241003}},"82a79514d4cc439abb4df14560d5cd36":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83af5b0873d94c6ba61a62cea77de792":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f246b1a9850a4fb7a60d18ab39460a6d","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07487c7811fb45c18ff93a63abdec100","tabbable":null,"tooltip":null,"value":20}},"8c2549c749394bc5b38f089948fb7e9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e0517f49d1d84197b7f59057bb81490a","placeholder":"​","style":"IPY_MODEL_65a015ea58b248049139e4c46f47adf8","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"94fa07a427ae45259ff5f9970f68b0b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a79039f6fb864b72af7f43b25c3a9fb5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adc080fd04e64214bb4fc228e79610ca":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae15586675d9490099f2fc9de55b0bd9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afcd0fcba8b34ff68c6392fea7505756":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_051418f578d34d5dba2dd359d1109880","max":1408,"min":0,"orientation":"horizontal","style":"IPY_MODEL_494ad401c8c04f7780d3fdcf28632f69","tabbable":null,"tooltip":null,"value":1408}},"b5e9847b85804123a9de68295ab93ff9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_64cb32030ade4d21b675b5a4d28b7368","placeholder":"​","style":"IPY_MODEL_fabb9feff99943f5aa3f82a69b38993e","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"b822667faaa74c6ab01c395748c0d47d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b9285e62d60e475f8fe4f4db3b0895c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b982186c460242888653a74546793c62":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_6dad674ae6014198b9825dca9c005214","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bf8897275cc4b19b4e3f90092c64b7a","tabbable":null,"tooltip":null,"value":636}},"ba9518850c7f4c0fb18cce654abd3458":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbd6e0469beb47bc81c1d50093750366":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc40890548b440d7a57cc74c5ecaada6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_24e5091b6b59499ab5e01101dd58a40c","placeholder":"​","style":"IPY_MODEL_d3f8231f211844ad81034de30ea99aca","tabbable":null,"tooltip":null,"value":" 17.5M/17.5M [00:00&lt;00:00, 42.5MB/s]"}},"c09d4da5befe439abd3c51b5a4bf6a8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c1d4fd8e00ea4acf9caa655da9bbf161":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52315e8d8a8478db82f6f4e06d2b83e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbcbf6cfafe441518fe22d7f540d7495","IPY_MODEL_4ac199f5d688449f8259b15177201b13","IPY_MODEL_12ef87ecaadb45a6a4578de95bc1f6aa"],"layout":"IPY_MODEL_170fdc6e77ce41639028d5869b5821f3","tabbable":null,"tooltip":null}},"c83eed9a0de6490fbb9ef6f61e9b263d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9437890478b4c3eb5a165f75a3aac84","IPY_MODEL_0a945edce7ca47cba745556b5ce445b3","IPY_MODEL_5f5a966543e34b8584846bf6561635b3"],"layout":"IPY_MODEL_5f8b3662480f45ffb7ad6bb7a36ca378","tabbable":null,"tooltip":null}},"c9375635b68147729a7b2cf82f4df4be":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2c43e516b2264a5bb610d776e4b837cf","placeholder":"​","style":"IPY_MODEL_c09d4da5befe439abd3c51b5a4bf6a8d","tabbable":null,"tooltip":null,"value":" 636/636 [00:00&lt;00:00, 64.9kB/s]"}},"ca776aa684d34788ae9b58fbb0295d62":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cd7a755925f7436681fff8b21664efd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c1d4fd8e00ea4acf9caa655da9bbf161","placeholder":"​","style":"IPY_MODEL_b9285e62d60e475f8fe4f4db3b0895c1","tabbable":null,"tooltip":null,"value":"tokenizer.json: 100%"}},"cf160b91f48a4b4e98be2292f688d61d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d150968782ef4535b7b433f9288d6b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3f8231f211844ad81034de30ea99aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d6421c66391e4114885675b48c2bfb83":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d9437890478b4c3eb5a165f75a3aac84":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_663e676afaa1484a8e142e7b28c01bab","placeholder":"​","style":"IPY_MODEL_0413a15497fb46208605c5c57267b8c6","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"db33d80dd295427ab4ebe0915b2ec4ac":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfab0d4df9684dffaeb90380707921e6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0517f49d1d84197b7f59057bb81490a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e667f0c76d7f4bbe96de8ccaa0fc11de":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb3db409e384fa8be50a629696c13ad":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13215505b5e436ba039de631320b671":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f246b1a9850a4fb7a60d18ab39460a6d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5d2db26e61b468b9864cad115489369":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4a27cd4f26154aea91ab5be4ca458f87","placeholder":"​","style":"IPY_MODEL_f63f2ba8cd5349a89621366b4fdd176d","tabbable":null,"tooltip":null,"value":" 6.13G/6.13G [02:25&lt;00:00, 42.0MB/s]"}},"f63f2ba8cd5349a89621366b4fdd176d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f8f85824a9ce4b13a47c99ca2eec1b63":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0a90b39003c34272b7da8d9d27847801","placeholder":"​","style":"IPY_MODEL_0f2e7ed1ac0f4931811e9d8df040901e","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"fabb9feff99943f5aa3f82a69b38993e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fbcbf6cfafe441518fe22d7f540d7495":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cf160b91f48a4b4e98be2292f688d61d","placeholder":"​","style":"IPY_MODEL_94fa07a427ae45259ff5f9970f68b0b3","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate peft bitsandbytes transformers trl unsloth optree","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:53:28.984701Z","iopub.execute_input":"2025-03-25T13:53:28.985039Z","iopub.status.idle":"2025-03-25T13:56:39.090773Z","shell.execute_reply.started":"2025-03-25T13:53:28.985011Z","shell.execute_reply":"2025-03-25T13:56:39.089733Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nCollecting peft\n  Downloading peft-0.15.0-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting trl\n  Downloading trl-0.16.0-py3-none-any.whl.metadata (12 kB)\nCollecting unsloth\n  Downloading unsloth-2025.3.18-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (0.12.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\nCollecting huggingface-hub>=0.21.0 (from accelerate)\n  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.2.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.8.1)\nCollecting transformers\n  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting unsloth_zoo>=2025.3.14 (from unsloth)\n  Downloading unsloth_zoo-2025.3.16-py3-none-any.whl.metadata (8.0 kB)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.17-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.0)\nCollecting trl\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nCollecting hf_transfer (from unsloth)\n  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting diffusers (from unsloth)\n  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.19.1+cu121)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree) (4.12.2)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->trl) (3.10.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.3.14->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.3.14->unsloth) (10.4.0)\nCollecting torch>=1.10.0 (from accelerate)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting sympy==1.13.1 (from torch>=1.10.0->accelerate)\n  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->trl) (4.0.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.20.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\nDownloading peft-0.15.0-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth-2025.3.18-py3-none-any.whl (192 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.3.16-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.9/126.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m975.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.17-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf_transfer, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tyro, tokenizers, nvidia-cusolver-cu12, diffusers, transformers, torch, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, peft, unsloth_zoo, unsloth\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.3\n    Uninstalling sympy-1.13.3:\n      Successfully uninstalled sympy-1.13.3\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.1+cu121\n    Uninstalling torch-2.4.1+cu121:\n      Successfully uninstalled torch-2.4.1+cu121\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.1+cu121\n    Uninstalling torchvision-0.19.1+cu121:\n      Successfully uninstalled torchvision-0.19.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.6.0 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.3 cut_cross_entropy-25.1.1 diffusers-0.32.2 hf_transfer-0.1.9 huggingface-hub-0.29.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 peft-0.15.0 shtab-1.7.1 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 torchvision-0.21.0 transformers-4.50.0 triton-3.2.0 trl-0.15.2 tyro-0.9.17 unsloth-2025.3.18 unsloth_zoo-2025.3.16 xformers-0.0.29.post3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport joblib\nimport warnings\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import (LongformerForSequenceClassification, LongformerTokenizerFast,\n                          Trainer, TrainingArguments, DataCollatorWithPadding)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:56:39.091986Z","iopub.execute_input":"2025-03-25T13:56:39.092279Z","iopub.status.idle":"2025-03-25T13:56:53.367974Z","shell.execute_reply.started":"2025-03-25T13:56:39.092248Z","shell.execute_reply":"2025-03-25T13:56:53.366957Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class CFG:\n    checkpoint = \"allenai/longformer-base-4096\"\n    max_length = 2048\n    per_device_train_batch_size = 8\n    per_device_eval_batch_size = 16\n    gradient_accumulation_steps = 2\n    n_epochs = 3\n    lr = 2e-5\n    warmup_steps = 20\n    lora_r = 8\n    lora_alpha = 16\n    lora_dropout = 0.1\n    lora_bias = \"none\"\n    seed = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:56:53.369646Z","iopub.execute_input":"2025-03-25T13:56:53.370116Z","iopub.status.idle":"2025-03-25T13:56:53.374211Z","shell.execute_reply.started":"2025-03-25T13:56:53.370095Z","shell.execute_reply":"2025-03-25T13:56:53.373155Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:56:53.375265Z","iopub.execute_input":"2025-03-25T13:56:53.375556Z","iopub.status.idle":"2025-03-25T13:56:53.388191Z","shell.execute_reply.started":"2025-03-25T13:56:53.375534Z","shell.execute_reply":"2025-03-25T13:56:53.387382Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\").reset_index(drop=True)\ndataset[\"winner\"] = dataset[\"winner\"].map({\"model_a\": 0, \"model_b\": 1})\n\ntrain, test = train_test_split(dataset, test_size=0.2, random_state=1)\nval, test = train_test_split(test, test_size=0.5, random_state=1)\n\ntrain = Dataset.from_pandas(train.sample(10000))\nval = Dataset.from_pandas(val)\ntest = Dataset.from_pandas(test)\n\ntokenizer = LongformerTokenizerFast.from_pretrained(CFG.checkpoint)\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:15:14.282317Z","iopub.execute_input":"2025-03-25T14:15:14.282820Z","iopub.status.idle":"2025-03-25T14:15:17.402186Z","shell.execute_reply.started":"2025-03-25T14:15:14.282781Z","shell.execute_reply":"2025-03-25T14:15:17.401497Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def encode(batch):\n    texts = [f\"<prompt>: {p}\\n\\n<response_a>: {a}\\n\\n<response_b>: {b}\" \n             for p, a, b in zip(batch[\"prompt\"], batch[\"response_a\"], batch[\"response_b\"])]\n    tokenized = tokenizer(texts, max_length=CFG.max_length, truncation=True, padding=\"max_length\")\n    return {**tokenized, \"labels\": batch[\"winner\"]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:15:17.403111Z","iopub.execute_input":"2025-03-25T14:15:17.403337Z","iopub.status.idle":"2025-03-25T14:15:17.407652Z","shell.execute_reply.started":"2025-03-25T14:15:17.403318Z","shell.execute_reply":"2025-03-25T14:15:17.406811Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train = train.map(encode, batched=True)\nval = val.map(encode, batched=True)\ntest = test.map(encode, batched=True)\n\nlora_config = LoraConfig(\n    r=CFG.lora_r,\n    lora_alpha=CFG.lora_alpha,\n    target_modules=[\"query\", \"value\"],\n    lora_dropout=CFG.lora_dropout,\n    bias=CFG.lora_bias,\n    task_type=TaskType.SEQ_CLS,\n)\n\nmodel = LongformerForSequenceClassification.from_pretrained(\n    CFG.checkpoint,\n    num_labels=2,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\n\nmodel.config.use_cache = False\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:15:17.408862Z","iopub.execute_input":"2025-03-25T14:15:17.409099Z","iopub.status.idle":"2025-03-25T14:16:12.639907Z","shell.execute_reply.started":"2025-03-25T14:15:17.409078Z","shell.execute_reply":"2025-03-25T14:16:12.639200Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5337ba7713a4cf8a9e5dd2d5f00a26a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4844 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69991908816849b38463ff474338e651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4844 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69b1295d53fe4672814ef3abf7ee65d0"}},"metadata":{}},{"name":"stderr","text":"Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from transformers import TrainerCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:16:12.641022Z","iopub.execute_input":"2025-03-25T14:16:12.641316Z","iopub.status.idle":"2025-03-25T14:16:12.645083Z","shell.execute_reply.started":"2025-03-25T14:16:12.641284Z","shell.execute_reply":"2025-03-25T14:16:12.644246Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds = eval_preds.predictions\n    labels = eval_preds.label_ids\n    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n    loss = log_loss(y_true=labels, y_pred=probs)\n    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n    return {\"acc\": acc, \"log_loss\": loss}\n\nclass LoggingCallback(TrainerCallback):\n    def on_step_end(self, args, state, control, **kwargs):\n        if state.global_step % 10 == 0:  # Log every 10 steps\n            if state.log_history and 'loss' in state.log_history[-1]:\n                print(f\"Step {state.global_step}: Loss = {state.log_history[-1]['loss']}, All = {state.log_history[-1]}\")\n\ntraining_args = TrainingArguments(\n    output_dir=\"longformer_finetuned\",\n    num_train_epochs=CFG.n_epochs,\n    per_device_train_batch_size=CFG.per_device_train_batch_size,\n    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    optim=\"adamw_torch\",\n    fp16=True,\n    learning_rate=CFG.lr,\n    warmup_steps=CFG.warmup_steps,\n    logging_dir=\"logs\",\n    logging_steps=10,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:16:12.645820Z","iopub.execute_input":"2025-03-25T14:16:12.646027Z","iopub.status.idle":"2025-03-25T14:16:12.686032Z","shell.execute_reply.started":"2025-03-25T14:16:12.646009Z","shell.execute_reply":"2025-03-25T14:16:12.685454Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train,\n    eval_dataset=val,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    callbacks=[LoggingCallback()],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:16:12.686838Z","iopub.execute_input":"2025-03-25T14:16:12.687117Z","iopub.status.idle":"2025-03-25T14:16:12.699711Z","shell.execute_reply.started":"2025-03-25T14:16:12.687087Z","shell.execute_reply":"2025-03-25T14:16:12.699041Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:16:12.701255Z","iopub.execute_input":"2025-03-25T14:16:12.701526Z","iopub.status.idle":"2025-03-25T18:50:54.184540Z","shell.execute_reply.started":"2025-03-25T14:16:12.701494Z","shell.execute_reply":"2025-03-25T18:50:54.183751Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1875/1875 4:34:33, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Acc</th>\n      <th>Log Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.697000</td>\n      <td>0.693223</td>\n      <td>0.496697</td>\n      <td>0.693222</td>\n      <td>594.274400</td>\n      <td>8.151000</td>\n      <td>0.510000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.697200</td>\n      <td>0.693403</td>\n      <td>0.507845</td>\n      <td>0.693405</td>\n      <td>593.862700</td>\n      <td>8.157000</td>\n      <td>0.510000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.697700</td>\n      <td>0.693082</td>\n      <td>0.504335</td>\n      <td>0.693080</td>\n      <td>600.746100</td>\n      <td>8.063000</td>\n      <td>0.504000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Step 20: Loss = 0.6967, All = {'loss': 0.6967, 'grad_norm': 3.047994613647461, 'learning_rate': 1e-05, 'epoch': 0.016, 'step': 10}\nStep 30: Loss = 0.6955, All = {'loss': 0.6955, 'grad_norm': 1.8335925340652466, 'learning_rate': 2e-05, 'epoch': 0.032, 'step': 20}\nStep 40: Loss = 0.7059, All = {'loss': 0.7059, 'grad_norm': 2.5207717418670654, 'learning_rate': 1.9892183288409707e-05, 'epoch': 0.048, 'step': 30}\nStep 50: Loss = 0.6915, All = {'loss': 0.6915, 'grad_norm': 0.9613805413246155, 'learning_rate': 1.978436657681941e-05, 'epoch': 0.064, 'step': 40}\nStep 60: Loss = 0.6987, All = {'loss': 0.6987, 'grad_norm': 2.152090072631836, 'learning_rate': 1.9676549865229113e-05, 'epoch': 0.08, 'step': 50}\nStep 70: Loss = 0.6976, All = {'loss': 0.6976, 'grad_norm': 1.2096996307373047, 'learning_rate': 1.9568733153638815e-05, 'epoch': 0.096, 'step': 60}\nStep 80: Loss = 0.6903, All = {'loss': 0.6903, 'grad_norm': 1.8332371711730957, 'learning_rate': 1.946091644204852e-05, 'epoch': 0.112, 'step': 70}\nStep 90: Loss = 0.6884, All = {'loss': 0.6884, 'grad_norm': 0.8988311290740967, 'learning_rate': 1.9353099730458222e-05, 'epoch': 0.128, 'step': 80}\nStep 100: Loss = 0.6938, All = {'loss': 0.6938, 'grad_norm': 1.244303584098816, 'learning_rate': 1.9245283018867927e-05, 'epoch': 0.144, 'step': 90}\nStep 110: Loss = 0.7027, All = {'loss': 0.7027, 'grad_norm': 0.9348532557487488, 'learning_rate': 1.913746630727763e-05, 'epoch': 0.16, 'step': 100}\nStep 120: Loss = 0.6964, All = {'loss': 0.6964, 'grad_norm': 1.6845688819885254, 'learning_rate': 1.9029649595687334e-05, 'epoch': 0.176, 'step': 110}\nStep 130: Loss = 0.6988, All = {'loss': 0.6988, 'grad_norm': 1.8476839065551758, 'learning_rate': 1.8921832884097035e-05, 'epoch': 0.192, 'step': 120}\nStep 140: Loss = 0.6864, All = {'loss': 0.6864, 'grad_norm': 2.9450671672821045, 'learning_rate': 1.881401617250674e-05, 'epoch': 0.208, 'step': 130}\nStep 150: Loss = 0.699, All = {'loss': 0.699, 'grad_norm': 0.8556079268455505, 'learning_rate': 1.8706199460916442e-05, 'epoch': 0.224, 'step': 140}\nStep 160: Loss = 0.6891, All = {'loss': 0.6891, 'grad_norm': 0.7120254635810852, 'learning_rate': 1.8598382749326147e-05, 'epoch': 0.24, 'step': 150}\nStep 170: Loss = 0.6854, All = {'loss': 0.6854, 'grad_norm': 2.632875680923462, 'learning_rate': 1.8490566037735852e-05, 'epoch': 0.256, 'step': 160}\nStep 180: Loss = 0.7046, All = {'loss': 0.7046, 'grad_norm': 2.2061030864715576, 'learning_rate': 1.8382749326145554e-05, 'epoch': 0.272, 'step': 170}\nStep 190: Loss = 0.6813, All = {'loss': 0.6813, 'grad_norm': 2.9663286209106445, 'learning_rate': 1.827493261455526e-05, 'epoch': 0.288, 'step': 180}\nStep 200: Loss = 0.6829, All = {'loss': 0.6829, 'grad_norm': 0.7900863885879517, 'learning_rate': 1.816711590296496e-05, 'epoch': 0.304, 'step': 190}\nStep 210: Loss = 0.7005, All = {'loss': 0.7005, 'grad_norm': 0.8551158905029297, 'learning_rate': 1.8059299191374666e-05, 'epoch': 0.32, 'step': 200}\nStep 220: Loss = 0.7006, All = {'loss': 0.7006, 'grad_norm': 1.4937191009521484, 'learning_rate': 1.7951482479784367e-05, 'epoch': 0.336, 'step': 210}\nStep 230: Loss = 0.6854, All = {'loss': 0.6854, 'grad_norm': 1.8517006635665894, 'learning_rate': 1.7843665768194072e-05, 'epoch': 0.352, 'step': 220}\nStep 240: Loss = 0.686, All = {'loss': 0.686, 'grad_norm': 2.455357551574707, 'learning_rate': 1.7735849056603774e-05, 'epoch': 0.368, 'step': 230}\nStep 250: Loss = 0.6942, All = {'loss': 0.6942, 'grad_norm': 2.080463171005249, 'learning_rate': 1.762803234501348e-05, 'epoch': 0.384, 'step': 240}\nStep 260: Loss = 0.6907, All = {'loss': 0.6907, 'grad_norm': 1.5424857139587402, 'learning_rate': 1.752021563342318e-05, 'epoch': 0.4, 'step': 250}\nStep 270: Loss = 0.6956, All = {'loss': 0.6956, 'grad_norm': 1.2655534744262695, 'learning_rate': 1.7412398921832886e-05, 'epoch': 0.416, 'step': 260}\nStep 280: Loss = 0.6929, All = {'loss': 0.6929, 'grad_norm': 1.2225942611694336, 'learning_rate': 1.7304582210242588e-05, 'epoch': 0.432, 'step': 270}\nStep 290: Loss = 0.6993, All = {'loss': 0.6993, 'grad_norm': 0.933671236038208, 'learning_rate': 1.7196765498652293e-05, 'epoch': 0.448, 'step': 280}\nStep 300: Loss = 0.6858, All = {'loss': 0.6858, 'grad_norm': 1.908589243888855, 'learning_rate': 1.7088948787061998e-05, 'epoch': 0.464, 'step': 290}\nStep 310: Loss = 0.6938, All = {'loss': 0.6938, 'grad_norm': 1.4111859798431396, 'learning_rate': 1.69811320754717e-05, 'epoch': 0.48, 'step': 300}\nStep 320: Loss = 0.6819, All = {'loss': 0.6819, 'grad_norm': 1.1132372617721558, 'learning_rate': 1.6873315363881405e-05, 'epoch': 0.496, 'step': 310}\nStep 330: Loss = 0.7031, All = {'loss': 0.7031, 'grad_norm': 2.9661309719085693, 'learning_rate': 1.6765498652291106e-05, 'epoch': 0.512, 'step': 320}\nStep 340: Loss = 0.6913, All = {'loss': 0.6913, 'grad_norm': 1.1126084327697754, 'learning_rate': 1.6657681940700808e-05, 'epoch': 0.528, 'step': 330}\nStep 350: Loss = 0.6983, All = {'loss': 0.6983, 'grad_norm': 1.7389123439788818, 'learning_rate': 1.6549865229110513e-05, 'epoch': 0.544, 'step': 340}\nStep 360: Loss = 0.695, All = {'loss': 0.695, 'grad_norm': 3.7437267303466797, 'learning_rate': 1.6442048517520218e-05, 'epoch': 0.56, 'step': 350}\nStep 370: Loss = 0.6805, All = {'loss': 0.6805, 'grad_norm': 1.001872181892395, 'learning_rate': 1.633423180592992e-05, 'epoch': 0.576, 'step': 360}\nStep 380: Loss = 0.6991, All = {'loss': 0.6991, 'grad_norm': 0.7493778467178345, 'learning_rate': 1.6226415094339625e-05, 'epoch': 0.592, 'step': 370}\nStep 390: Loss = 0.704, All = {'loss': 0.704, 'grad_norm': 1.0520868301391602, 'learning_rate': 1.6118598382749326e-05, 'epoch': 0.608, 'step': 380}\nStep 400: Loss = 0.709, All = {'loss': 0.709, 'grad_norm': 3.352581262588501, 'learning_rate': 1.601078167115903e-05, 'epoch': 0.624, 'step': 390}\nStep 410: Loss = 0.6915, All = {'loss': 0.6915, 'grad_norm': 2.0189547538757324, 'learning_rate': 1.5902964959568733e-05, 'epoch': 0.64, 'step': 400}\nStep 420: Loss = 0.6919, All = {'loss': 0.6919, 'grad_norm': 1.8549169301986694, 'learning_rate': 1.5795148247978438e-05, 'epoch': 0.656, 'step': 410}\nStep 430: Loss = 0.6931, All = {'loss': 0.6931, 'grad_norm': 1.48796808719635, 'learning_rate': 1.5687331536388143e-05, 'epoch': 0.672, 'step': 420}\nStep 440: Loss = 0.7017, All = {'loss': 0.7017, 'grad_norm': 1.2138478755950928, 'learning_rate': 1.5579514824797845e-05, 'epoch': 0.688, 'step': 430}\nStep 450: Loss = 0.7012, All = {'loss': 0.7012, 'grad_norm': 1.2856379747390747, 'learning_rate': 1.547169811320755e-05, 'epoch': 0.704, 'step': 440}\nStep 460: Loss = 0.6933, All = {'loss': 0.6933, 'grad_norm': 2.3476407527923584, 'learning_rate': 1.5363881401617252e-05, 'epoch': 0.72, 'step': 450}\nStep 470: Loss = 0.6886, All = {'loss': 0.6886, 'grad_norm': 1.2809065580368042, 'learning_rate': 1.5256064690026955e-05, 'epoch': 0.736, 'step': 460}\nStep 480: Loss = 0.6879, All = {'loss': 0.6879, 'grad_norm': 1.0301539897918701, 'learning_rate': 1.5148247978436658e-05, 'epoch': 0.752, 'step': 470}\nStep 490: Loss = 0.6967, All = {'loss': 0.6967, 'grad_norm': 1.03388512134552, 'learning_rate': 1.5040431266846362e-05, 'epoch': 0.768, 'step': 480}\nStep 500: Loss = 0.6994, All = {'loss': 0.6994, 'grad_norm': 0.7463412284851074, 'learning_rate': 1.4932614555256067e-05, 'epoch': 0.784, 'step': 490}\nStep 510: Loss = 0.6904, All = {'loss': 0.6904, 'grad_norm': 1.124135136604309, 'learning_rate': 1.482479784366577e-05, 'epoch': 0.8, 'step': 500}\nStep 520: Loss = 0.6928, All = {'loss': 0.6928, 'grad_norm': 1.1282086372375488, 'learning_rate': 1.4716981132075472e-05, 'epoch': 0.816, 'step': 510}\nStep 530: Loss = 0.7033, All = {'loss': 0.7033, 'grad_norm': 3.7057955265045166, 'learning_rate': 1.4609164420485175e-05, 'epoch': 0.832, 'step': 520}\nStep 540: Loss = 0.6906, All = {'loss': 0.6906, 'grad_norm': 1.3163143396377563, 'learning_rate': 1.4501347708894879e-05, 'epoch': 0.848, 'step': 530}\nStep 550: Loss = 0.6968, All = {'loss': 0.6968, 'grad_norm': 1.9408231973648071, 'learning_rate': 1.4393530997304584e-05, 'epoch': 0.864, 'step': 540}\nStep 560: Loss = 0.7022, All = {'loss': 0.7022, 'grad_norm': 2.3050668239593506, 'learning_rate': 1.4285714285714287e-05, 'epoch': 0.88, 'step': 550}\nStep 570: Loss = 0.6946, All = {'loss': 0.6946, 'grad_norm': 1.0805470943450928, 'learning_rate': 1.417789757412399e-05, 'epoch': 0.896, 'step': 560}\nStep 580: Loss = 0.698, All = {'loss': 0.698, 'grad_norm': 1.7737717628479004, 'learning_rate': 1.4070080862533696e-05, 'epoch': 0.912, 'step': 570}\nStep 590: Loss = 0.6973, All = {'loss': 0.6973, 'grad_norm': 2.2710683345794678, 'learning_rate': 1.3962264150943397e-05, 'epoch': 0.928, 'step': 580}\nStep 600: Loss = 0.702, All = {'loss': 0.702, 'grad_norm': 3.8810129165649414, 'learning_rate': 1.38544474393531e-05, 'epoch': 0.944, 'step': 590}\nStep 610: Loss = 0.6917, All = {'loss': 0.6917, 'grad_norm': 1.9154558181762695, 'learning_rate': 1.3746630727762804e-05, 'epoch': 0.96, 'step': 600}\nStep 620: Loss = 0.695, All = {'loss': 0.695, 'grad_norm': 1.4344396591186523, 'learning_rate': 1.3638814016172507e-05, 'epoch': 0.976, 'step': 610}\nStep 640: Loss = 0.7032, All = {'loss': 0.7032, 'grad_norm': 1.1447099447250366, 'learning_rate': 1.3423180592991916e-05, 'epoch': 1.008, 'step': 630}\nStep 650: Loss = 0.6904, All = {'loss': 0.6904, 'grad_norm': 2.2480976581573486, 'learning_rate': 1.3315363881401617e-05, 'epoch': 1.024, 'step': 640}\nStep 660: Loss = 0.6963, All = {'loss': 0.6963, 'grad_norm': 1.8637702465057373, 'learning_rate': 1.320754716981132e-05, 'epoch': 1.04, 'step': 650}\nStep 670: Loss = 0.6902, All = {'loss': 0.6902, 'grad_norm': 2.0945239067077637, 'learning_rate': 1.3099730458221024e-05, 'epoch': 1.056, 'step': 660}\nStep 680: Loss = 0.6977, All = {'loss': 0.6977, 'grad_norm': 0.98064786195755, 'learning_rate': 1.299191374663073e-05, 'epoch': 1.072, 'step': 670}\nStep 690: Loss = 0.6917, All = {'loss': 0.6917, 'grad_norm': 1.218762755393982, 'learning_rate': 1.2884097035040433e-05, 'epoch': 1.088, 'step': 680}\nStep 700: Loss = 0.6899, All = {'loss': 0.6899, 'grad_norm': 1.2933114767074585, 'learning_rate': 1.2776280323450136e-05, 'epoch': 1.104, 'step': 690}\nStep 710: Loss = 0.6915, All = {'loss': 0.6915, 'grad_norm': 1.3496427536010742, 'learning_rate': 1.2668463611859841e-05, 'epoch': 1.12, 'step': 700}\nStep 720: Loss = 0.6889, All = {'loss': 0.6889, 'grad_norm': 1.9942179918289185, 'learning_rate': 1.2560646900269541e-05, 'epoch': 1.1360000000000001, 'step': 710}\nStep 730: Loss = 0.6905, All = {'loss': 0.6905, 'grad_norm': 1.756956934928894, 'learning_rate': 1.2452830188679246e-05, 'epoch': 1.152, 'step': 720}\nStep 740: Loss = 0.6953, All = {'loss': 0.6953, 'grad_norm': 1.3403127193450928, 'learning_rate': 1.234501347708895e-05, 'epoch': 1.168, 'step': 730}\nStep 750: Loss = 0.6909, All = {'loss': 0.6909, 'grad_norm': 1.0800538063049316, 'learning_rate': 1.2237196765498653e-05, 'epoch': 1.184, 'step': 740}\nStep 760: Loss = 0.6863, All = {'loss': 0.6863, 'grad_norm': 0.7928764820098877, 'learning_rate': 1.2129380053908358e-05, 'epoch': 1.2, 'step': 750}\nStep 770: Loss = 0.691, All = {'loss': 0.691, 'grad_norm': 3.4043169021606445, 'learning_rate': 1.2021563342318061e-05, 'epoch': 1.216, 'step': 760}\nStep 780: Loss = 0.7045, All = {'loss': 0.7045, 'grad_norm': 1.0776413679122925, 'learning_rate': 1.1913746630727763e-05, 'epoch': 1.232, 'step': 770}\nStep 790: Loss = 0.6896, All = {'loss': 0.6896, 'grad_norm': 1.8952449560165405, 'learning_rate': 1.1805929919137466e-05, 'epoch': 1.248, 'step': 780}\nStep 800: Loss = 0.6909, All = {'loss': 0.6909, 'grad_norm': 0.9488252997398376, 'learning_rate': 1.169811320754717e-05, 'epoch': 1.264, 'step': 790}\nStep 810: Loss = 0.6942, All = {'loss': 0.6942, 'grad_norm': 0.8618261814117432, 'learning_rate': 1.1590296495956875e-05, 'epoch': 1.28, 'step': 800}\nStep 820: Loss = 0.6998, All = {'loss': 0.6998, 'grad_norm': 0.9787291288375854, 'learning_rate': 1.1482479784366578e-05, 'epoch': 1.296, 'step': 810}\nStep 830: Loss = 0.6964, All = {'loss': 0.6964, 'grad_norm': 1.9333957433700562, 'learning_rate': 1.1374663072776282e-05, 'epoch': 1.312, 'step': 820}\nStep 840: Loss = 0.6869, All = {'loss': 0.6869, 'grad_norm': 0.809483528137207, 'learning_rate': 1.1266846361185985e-05, 'epoch': 1.328, 'step': 830}\nStep 850: Loss = 0.6859, All = {'loss': 0.6859, 'grad_norm': 0.9866440296173096, 'learning_rate': 1.1159029649595687e-05, 'epoch': 1.3439999999999999, 'step': 840}\nStep 860: Loss = 0.6917, All = {'loss': 0.6917, 'grad_norm': 4.568559169769287, 'learning_rate': 1.1051212938005392e-05, 'epoch': 1.3599999999999999, 'step': 850}\nStep 870: Loss = 0.6919, All = {'loss': 0.6919, 'grad_norm': 0.8211456537246704, 'learning_rate': 1.0943396226415095e-05, 'epoch': 1.376, 'step': 860}\nStep 880: Loss = 0.6893, All = {'loss': 0.6893, 'grad_norm': 0.9973580241203308, 'learning_rate': 1.0835579514824798e-05, 'epoch': 1.392, 'step': 870}\nStep 890: Loss = 0.6887, All = {'loss': 0.6887, 'grad_norm': 1.3344939947128296, 'learning_rate': 1.0727762803234503e-05, 'epoch': 1.408, 'step': 880}\nStep 900: Loss = 0.6891, All = {'loss': 0.6891, 'grad_norm': 1.5802890062332153, 'learning_rate': 1.0619946091644207e-05, 'epoch': 1.424, 'step': 890}\nStep 910: Loss = 0.6903, All = {'loss': 0.6903, 'grad_norm': 4.1694512367248535, 'learning_rate': 1.0512129380053909e-05, 'epoch': 1.44, 'step': 900}\nStep 920: Loss = 0.6854, All = {'loss': 0.6854, 'grad_norm': 0.7846667766571045, 'learning_rate': 1.0404312668463612e-05, 'epoch': 1.456, 'step': 910}\nStep 930: Loss = 0.6935, All = {'loss': 0.6935, 'grad_norm': 1.6523619890213013, 'learning_rate': 1.0296495956873315e-05, 'epoch': 1.472, 'step': 920}\nStep 940: Loss = 0.6985, All = {'loss': 0.6985, 'grad_norm': 1.7349194288253784, 'learning_rate': 1.018867924528302e-05, 'epoch': 1.488, 'step': 930}\nStep 950: Loss = 0.6909, All = {'loss': 0.6909, 'grad_norm': 1.1093226671218872, 'learning_rate': 1.0080862533692724e-05, 'epoch': 1.504, 'step': 940}\nStep 960: Loss = 0.6937, All = {'loss': 0.6937, 'grad_norm': 1.9002717733383179, 'learning_rate': 9.973045822102425e-06, 'epoch': 1.52, 'step': 950}\nStep 970: Loss = 0.6944, All = {'loss': 0.6944, 'grad_norm': 2.0846712589263916, 'learning_rate': 9.86522911051213e-06, 'epoch': 1.536, 'step': 960}\nStep 980: Loss = 0.6999, All = {'loss': 0.6999, 'grad_norm': 1.3550217151641846, 'learning_rate': 9.757412398921834e-06, 'epoch': 1.552, 'step': 970}\nStep 990: Loss = 0.6951, All = {'loss': 0.6951, 'grad_norm': 0.9115601778030396, 'learning_rate': 9.649595687331537e-06, 'epoch': 1.568, 'step': 980}\nStep 1000: Loss = 0.6942, All = {'loss': 0.6942, 'grad_norm': 0.6882449984550476, 'learning_rate': 9.54177897574124e-06, 'epoch': 1.584, 'step': 990}\nStep 1010: Loss = 0.6964, All = {'loss': 0.6964, 'grad_norm': 0.9014630913734436, 'learning_rate': 9.433962264150944e-06, 'epoch': 1.6, 'step': 1000}\nStep 1020: Loss = 0.7026, All = {'loss': 0.7026, 'grad_norm': 0.7085134387016296, 'learning_rate': 9.326145552560647e-06, 'epoch': 1.616, 'step': 1010}\nStep 1030: Loss = 0.6951, All = {'loss': 0.6951, 'grad_norm': 3.6290969848632812, 'learning_rate': 9.21832884097035e-06, 'epoch': 1.6320000000000001, 'step': 1020}\nStep 1040: Loss = 0.6931, All = {'loss': 0.6931, 'grad_norm': 5.525132179260254, 'learning_rate': 9.110512129380054e-06, 'epoch': 1.6480000000000001, 'step': 1030}\nStep 1050: Loss = 0.6892, All = {'loss': 0.6892, 'grad_norm': 1.2902836799621582, 'learning_rate': 9.002695417789759e-06, 'epoch': 1.6640000000000001, 'step': 1040}\nStep 1060: Loss = 0.6921, All = {'loss': 0.6921, 'grad_norm': 0.8350027203559875, 'learning_rate': 8.89487870619946e-06, 'epoch': 1.6800000000000002, 'step': 1050}\nStep 1070: Loss = 0.6889, All = {'loss': 0.6889, 'grad_norm': 0.7282032370567322, 'learning_rate': 8.787061994609166e-06, 'epoch': 1.696, 'step': 1060}\nStep 1080: Loss = 0.6965, All = {'loss': 0.6965, 'grad_norm': 1.1623849868774414, 'learning_rate': 8.67924528301887e-06, 'epoch': 1.712, 'step': 1070}\nStep 1090: Loss = 0.6974, All = {'loss': 0.6974, 'grad_norm': 1.2853752374649048, 'learning_rate': 8.571428571428571e-06, 'epoch': 1.728, 'step': 1080}\nStep 1100: Loss = 0.697, All = {'loss': 0.697, 'grad_norm': 0.9742271304130554, 'learning_rate': 8.463611859838276e-06, 'epoch': 1.744, 'step': 1090}\nStep 1110: Loss = 0.6921, All = {'loss': 0.6921, 'grad_norm': 0.8443034887313843, 'learning_rate': 8.35579514824798e-06, 'epoch': 1.76, 'step': 1100}\nStep 1120: Loss = 0.6956, All = {'loss': 0.6956, 'grad_norm': 1.9117995500564575, 'learning_rate': 8.247978436657683e-06, 'epoch': 1.776, 'step': 1110}\nStep 1130: Loss = 0.6962, All = {'loss': 0.6962, 'grad_norm': 1.480894923210144, 'learning_rate': 8.140161725067386e-06, 'epoch': 1.792, 'step': 1120}\nStep 1140: Loss = 0.695, All = {'loss': 0.695, 'grad_norm': 2.793468475341797, 'learning_rate': 8.03234501347709e-06, 'epoch': 1.808, 'step': 1130}\nStep 1150: Loss = 0.6915, All = {'loss': 0.6915, 'grad_norm': 1.6300089359283447, 'learning_rate': 7.924528301886793e-06, 'epoch': 1.8239999999999998, 'step': 1140}\nStep 1160: Loss = 0.6906, All = {'loss': 0.6906, 'grad_norm': 1.814308524131775, 'learning_rate': 7.816711590296496e-06, 'epoch': 1.8399999999999999, 'step': 1150}\nStep 1170: Loss = 0.6897, All = {'loss': 0.6897, 'grad_norm': 2.839207410812378, 'learning_rate': 7.7088948787062e-06, 'epoch': 1.8559999999999999, 'step': 1160}\nStep 1180: Loss = 0.6987, All = {'loss': 0.6987, 'grad_norm': 2.010524272918701, 'learning_rate': 7.601078167115904e-06, 'epoch': 1.8719999999999999, 'step': 1170}\nStep 1190: Loss = 0.6968, All = {'loss': 0.6968, 'grad_norm': 0.9297823905944824, 'learning_rate': 7.493261455525606e-06, 'epoch': 1.888, 'step': 1180}\nStep 1200: Loss = 0.6922, All = {'loss': 0.6922, 'grad_norm': 1.6587237119674683, 'learning_rate': 7.3854447439353106e-06, 'epoch': 1.904, 'step': 1190}\nStep 1210: Loss = 0.694, All = {'loss': 0.694, 'grad_norm': 1.7544564008712769, 'learning_rate': 7.277628032345015e-06, 'epoch': 1.92, 'step': 1200}\nStep 1220: Loss = 0.6908, All = {'loss': 0.6908, 'grad_norm': 1.0064455270767212, 'learning_rate': 7.169811320754717e-06, 'epoch': 1.936, 'step': 1210}\nStep 1230: Loss = 0.6968, All = {'loss': 0.6968, 'grad_norm': 1.3614469766616821, 'learning_rate': 7.061994609164421e-06, 'epoch': 1.952, 'step': 1220}\nStep 1240: Loss = 0.6922, All = {'loss': 0.6922, 'grad_norm': 0.9521207213401794, 'learning_rate': 6.954177897574125e-06, 'epoch': 1.968, 'step': 1230}\nStep 1250: Loss = 0.6966, All = {'loss': 0.6966, 'grad_norm': 1.0514616966247559, 'learning_rate': 6.846361185983828e-06, 'epoch': 1.984, 'step': 1240}\nStep 1270: Loss = 0.6902, All = {'loss': 0.6902, 'grad_norm': 2.3705224990844727, 'learning_rate': 6.630727762803235e-06, 'epoch': 2.016, 'step': 1260}\nStep 1280: Loss = 0.6961, All = {'loss': 0.6961, 'grad_norm': 1.1001818180084229, 'learning_rate': 6.522911051212939e-06, 'epoch': 2.032, 'step': 1270}\nStep 1290: Loss = 0.6953, All = {'loss': 0.6953, 'grad_norm': 1.0009543895721436, 'learning_rate': 6.415094339622642e-06, 'epoch': 2.048, 'step': 1280}\nStep 1300: Loss = 0.683, All = {'loss': 0.683, 'grad_norm': 1.0780878067016602, 'learning_rate': 6.307277628032346e-06, 'epoch': 2.064, 'step': 1290}\nStep 1310: Loss = 0.6991, All = {'loss': 0.6991, 'grad_norm': 1.3072350025177002, 'learning_rate': 6.199460916442049e-06, 'epoch': 2.08, 'step': 1300}\nStep 1320: Loss = 0.691, All = {'loss': 0.691, 'grad_norm': 1.8669102191925049, 'learning_rate': 6.091644204851752e-06, 'epoch': 2.096, 'step': 1310}\nStep 1330: Loss = 0.6913, All = {'loss': 0.6913, 'grad_norm': 1.0163756608963013, 'learning_rate': 5.983827493261456e-06, 'epoch': 2.112, 'step': 1320}\nStep 1340: Loss = 0.688, All = {'loss': 0.688, 'grad_norm': 0.9490236639976501, 'learning_rate': 5.8760107816711595e-06, 'epoch': 2.128, 'step': 1330}\nStep 1350: Loss = 0.6937, All = {'loss': 0.6937, 'grad_norm': 3.068927526473999, 'learning_rate': 5.768194070080863e-06, 'epoch': 2.144, 'step': 1340}\nStep 1360: Loss = 0.6946, All = {'loss': 0.6946, 'grad_norm': 3.4345269203186035, 'learning_rate': 5.660377358490566e-06, 'epoch': 2.16, 'step': 1350}\nStep 1370: Loss = 0.6872, All = {'loss': 0.6872, 'grad_norm': 2.611859083175659, 'learning_rate': 5.55256064690027e-06, 'epoch': 2.176, 'step': 1360}\nStep 1380: Loss = 0.6833, All = {'loss': 0.6833, 'grad_norm': 1.2059154510498047, 'learning_rate': 5.444743935309974e-06, 'epoch': 2.192, 'step': 1370}\nStep 1390: Loss = 0.6933, All = {'loss': 0.6933, 'grad_norm': 3.9433538913726807, 'learning_rate': 5.336927223719677e-06, 'epoch': 2.208, 'step': 1380}\nStep 1400: Loss = 0.6893, All = {'loss': 0.6893, 'grad_norm': 0.9940345287322998, 'learning_rate': 5.2291105121293805e-06, 'epoch': 2.224, 'step': 1390}\nStep 1410: Loss = 0.6952, All = {'loss': 0.6952, 'grad_norm': 0.9662030339241028, 'learning_rate': 5.121293800539085e-06, 'epoch': 2.24, 'step': 1400}\nStep 1420: Loss = 0.7033, All = {'loss': 0.7033, 'grad_norm': 3.036167860031128, 'learning_rate': 5.013477088948787e-06, 'epoch': 2.2560000000000002, 'step': 1410}\nStep 1430: Loss = 0.6854, All = {'loss': 0.6854, 'grad_norm': 2.0300331115722656, 'learning_rate': 4.905660377358491e-06, 'epoch': 2.2720000000000002, 'step': 1420}\nStep 1440: Loss = 0.6927, All = {'loss': 0.6927, 'grad_norm': 1.1280148029327393, 'learning_rate': 4.797843665768194e-06, 'epoch': 2.288, 'step': 1430}\nStep 1450: Loss = 0.6824, All = {'loss': 0.6824, 'grad_norm': 0.8459363579750061, 'learning_rate': 4.690026954177898e-06, 'epoch': 2.304, 'step': 1440}\nStep 1460: Loss = 0.6928, All = {'loss': 0.6928, 'grad_norm': 1.3273279666900635, 'learning_rate': 4.582210242587602e-06, 'epoch': 2.32, 'step': 1450}\nStep 1470: Loss = 0.6958, All = {'loss': 0.6958, 'grad_norm': 2.1396124362945557, 'learning_rate': 4.474393530997305e-06, 'epoch': 2.336, 'step': 1460}\nStep 1480: Loss = 0.6947, All = {'loss': 0.6947, 'grad_norm': 1.4088287353515625, 'learning_rate': 4.366576819407008e-06, 'epoch': 2.352, 'step': 1470}\nStep 1490: Loss = 0.688, All = {'loss': 0.688, 'grad_norm': 1.3505831956863403, 'learning_rate': 4.258760107816712e-06, 'epoch': 2.368, 'step': 1480}\nStep 1500: Loss = 0.6923, All = {'loss': 0.6923, 'grad_norm': 2.70900559425354, 'learning_rate': 4.150943396226416e-06, 'epoch': 2.384, 'step': 1490}\nStep 1510: Loss = 0.6911, All = {'loss': 0.6911, 'grad_norm': 1.7042245864868164, 'learning_rate': 4.043126684636119e-06, 'epoch': 2.4, 'step': 1500}\nStep 1520: Loss = 0.6892, All = {'loss': 0.6892, 'grad_norm': 1.9949381351470947, 'learning_rate': 3.935309973045822e-06, 'epoch': 2.416, 'step': 1510}\nStep 1530: Loss = 0.6921, All = {'loss': 0.6921, 'grad_norm': 1.6646993160247803, 'learning_rate': 3.827493261455526e-06, 'epoch': 2.432, 'step': 1520}\nStep 1540: Loss = 0.6952, All = {'loss': 0.6952, 'grad_norm': 1.0208417177200317, 'learning_rate': 3.7196765498652294e-06, 'epoch': 2.448, 'step': 1530}\nStep 1550: Loss = 0.6903, All = {'loss': 0.6903, 'grad_norm': 1.6592471599578857, 'learning_rate': 3.6118598382749332e-06, 'epoch': 2.464, 'step': 1540}\nStep 1560: Loss = 0.6992, All = {'loss': 0.6992, 'grad_norm': 2.7122151851654053, 'learning_rate': 3.5040431266846366e-06, 'epoch': 2.48, 'step': 1550}\nStep 1570: Loss = 0.6889, All = {'loss': 0.6889, 'grad_norm': 2.232250452041626, 'learning_rate': 3.3962264150943395e-06, 'epoch': 2.496, 'step': 1560}\nStep 1580: Loss = 0.6889, All = {'loss': 0.6889, 'grad_norm': 0.8919932842254639, 'learning_rate': 3.2884097035040433e-06, 'epoch': 2.512, 'step': 1570}\nStep 1590: Loss = 0.7023, All = {'loss': 0.7023, 'grad_norm': 0.8768005967140198, 'learning_rate': 3.1805929919137467e-06, 'epoch': 2.528, 'step': 1580}\nStep 1600: Loss = 0.6852, All = {'loss': 0.6852, 'grad_norm': 1.0607718229293823, 'learning_rate': 3.0727762803234505e-06, 'epoch': 2.544, 'step': 1590}\nStep 1610: Loss = 0.6963, All = {'loss': 0.6963, 'grad_norm': 1.634045958518982, 'learning_rate': 2.964959568733154e-06, 'epoch': 2.56, 'step': 1600}\nStep 1620: Loss = 0.6889, All = {'loss': 0.6889, 'grad_norm': 1.4731053113937378, 'learning_rate': 2.8571428571428573e-06, 'epoch': 2.576, 'step': 1610}\nStep 1630: Loss = 0.6918, All = {'loss': 0.6918, 'grad_norm': 1.161112666130066, 'learning_rate': 2.749326145552561e-06, 'epoch': 2.592, 'step': 1620}\nStep 1640: Loss = 0.6902, All = {'loss': 0.6902, 'grad_norm': 2.089690685272217, 'learning_rate': 2.6415094339622644e-06, 'epoch': 2.608, 'step': 1630}\nStep 1650: Loss = 0.6943, All = {'loss': 0.6943, 'grad_norm': 0.8717274069786072, 'learning_rate': 2.533692722371968e-06, 'epoch': 2.624, 'step': 1640}\nStep 1660: Loss = 0.6885, All = {'loss': 0.6885, 'grad_norm': 1.4394887685775757, 'learning_rate': 2.4258760107816716e-06, 'epoch': 2.64, 'step': 1650}\nStep 1670: Loss = 0.6968, All = {'loss': 0.6968, 'grad_norm': 2.169102191925049, 'learning_rate': 2.3180592991913745e-06, 'epoch': 2.656, 'step': 1660}\nStep 1680: Loss = 0.6893, All = {'loss': 0.6893, 'grad_norm': 2.5183067321777344, 'learning_rate': 2.2102425876010783e-06, 'epoch': 2.672, 'step': 1670}\nStep 1690: Loss = 0.6916, All = {'loss': 0.6916, 'grad_norm': 2.371396064758301, 'learning_rate': 2.1024258760107817e-06, 'epoch': 2.6879999999999997, 'step': 1680}\nStep 1700: Loss = 0.7007, All = {'loss': 0.7007, 'grad_norm': 0.889860987663269, 'learning_rate': 1.9946091644204855e-06, 'epoch': 2.7039999999999997, 'step': 1690}\nStep 1710: Loss = 0.6936, All = {'loss': 0.6936, 'grad_norm': 3.395465612411499, 'learning_rate': 1.8867924528301889e-06, 'epoch': 2.7199999999999998, 'step': 1700}\nStep 1720: Loss = 0.6904, All = {'loss': 0.6904, 'grad_norm': 1.8267767429351807, 'learning_rate': 1.7789757412398922e-06, 'epoch': 2.7359999999999998, 'step': 1710}\nStep 1730: Loss = 0.692, All = {'loss': 0.692, 'grad_norm': 1.6032487154006958, 'learning_rate': 1.6711590296495958e-06, 'epoch': 2.752, 'step': 1720}\nStep 1740: Loss = 0.6918, All = {'loss': 0.6918, 'grad_norm': 1.524707555770874, 'learning_rate': 1.5633423180592994e-06, 'epoch': 2.768, 'step': 1730}\nStep 1750: Loss = 0.691, All = {'loss': 0.691, 'grad_norm': 1.1353451013565063, 'learning_rate': 1.455525606469003e-06, 'epoch': 2.784, 'step': 1740}\nStep 1760: Loss = 0.6928, All = {'loss': 0.6928, 'grad_norm': 1.1006126403808594, 'learning_rate': 1.3477088948787062e-06, 'epoch': 2.8, 'step': 1750}\nStep 1770: Loss = 0.6899, All = {'loss': 0.6899, 'grad_norm': 1.2056140899658203, 'learning_rate': 1.2398921832884097e-06, 'epoch': 2.816, 'step': 1760}\nStep 1780: Loss = 0.6958, All = {'loss': 0.6958, 'grad_norm': 3.0576908588409424, 'learning_rate': 1.1320754716981133e-06, 'epoch': 2.832, 'step': 1770}\nStep 1790: Loss = 0.688, All = {'loss': 0.688, 'grad_norm': 1.1850284337997437, 'learning_rate': 1.0242587601078167e-06, 'epoch': 2.848, 'step': 1780}\nStep 1800: Loss = 0.6873, All = {'loss': 0.6873, 'grad_norm': 1.2242884635925293, 'learning_rate': 9.164420485175203e-07, 'epoch': 2.864, 'step': 1790}\nStep 1810: Loss = 0.6857, All = {'loss': 0.6857, 'grad_norm': 2.432504653930664, 'learning_rate': 8.086253369272238e-07, 'epoch': 2.88, 'step': 1800}\nStep 1820: Loss = 0.6811, All = {'loss': 0.6811, 'grad_norm': 0.9998303055763245, 'learning_rate': 7.008086253369272e-07, 'epoch': 2.896, 'step': 1810}\nStep 1830: Loss = 0.6868, All = {'loss': 0.6868, 'grad_norm': 2.234229803085327, 'learning_rate': 5.929919137466308e-07, 'epoch': 2.912, 'step': 1820}\nStep 1840: Loss = 0.6854, All = {'loss': 0.6854, 'grad_norm': 2.390415906906128, 'learning_rate': 4.851752021563343e-07, 'epoch': 2.928, 'step': 1830}\nStep 1850: Loss = 0.6936, All = {'loss': 0.6936, 'grad_norm': 1.6739673614501953, 'learning_rate': 3.773584905660378e-07, 'epoch': 2.944, 'step': 1840}\nStep 1860: Loss = 0.6925, All = {'loss': 0.6925, 'grad_norm': 0.8926920294761658, 'learning_rate': 2.6954177897574125e-07, 'epoch': 2.96, 'step': 1850}\nStep 1870: Loss = 0.6862, All = {'loss': 0.6862, 'grad_norm': 1.4681730270385742, 'learning_rate': 1.6172506738544476e-07, 'epoch': 2.976, 'step': 1860}\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1875, training_loss=0.6931615804036458, metrics={'train_runtime': 16481.106, 'train_samples_per_second': 1.82, 'train_steps_per_second': 0.114, 'total_flos': 3.973809586176e+16, 'train_loss': 0.6931615804036458, 'epoch': 3.0})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"y_true = test[\"winner\"]\nlogits = trainer.predict(test).predictions\ny_pred_probs = torch.from_numpy(logits).float().softmax(-1).numpy()\nacc = accuracy_score(y_true=y_true, y_pred=y_pred_probs.argmax(-1))\nprint(f\"Test - Accuracy: {acc:.4f}\") \n\njoblib.dump(y_pred_probs, f\"y_pred_probs_fold_test_acc_{acc:.6f}.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:50:54.185695Z","iopub.execute_input":"2025-03-25T18:50:54.186029Z","execution_failed":"2025-03-25T18:52:20.290Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 42/303 01:24 < 08:54, 0.49 it/s]\n    </div>\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-25T18:52:20.290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report((y_pred_probs[:, 0] <= 0.5).astype(int), y_true, digits=6))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-25T18:52:20.290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"/(y_pred_probs[:, 0] >= 0.5).astype(int)[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:10:25.793234Z","iopub.status.idle":"2025-03-25T14:10:25.793618Z","shell.execute_reply":"2025-03-25T14:10:25.793455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:10:25.794551Z","iopub.status.idle":"2025-03-25T14:10:25.794912Z","shell.execute_reply":"2025-03-25T14:10:25.794757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}