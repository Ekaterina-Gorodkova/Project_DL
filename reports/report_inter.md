## EDA

### Анализ набора данных

Наш анализ показывает, что набор данных хорошо сбалансирован. Значения для `model_a` и `model_b` практически одинаковы относительно целевой переменной `winner`, что указывает на равномерное распределение результатов между двумя моделями. Это позволяет проводить корректное сравнение их производительности.

---

#### 1. Распределение моделей

- **Частота использования моделей**:
  - На гистограмме, отображающей частоту использования моделей в качестве `model_a`, видно, какие модели применялись чаще, а какие — реже.
  - Аналогичная картина наблюдается и для `model_b`. Это дает полное представление о том, как распределены модели в наборе данных.
  - Например, если определенная модель используется чаще в качестве `model_a`, это может указывать на ее популярность или предпочтение в экспериментах.

---

#### 2. Языковое распределение

- **Основной язык**:
  - Набор данных в основном состоит из текстов на английском языке. Это может быть связано с тем, что английский является наиболее распространенным языком в подобных задачах.
- **Другие языки**:
  - Объем текстов на других языках значительно меньше. Это может повлиять на анализ и выводы, особенно если рассматриваются мультиязычные сценарии.
  - Рекомендуется учитывать этот дисбаланс при интерпретации результатов, чтобы избежать смещения в сторону английского языка.

---

#### 3. Длины запросов и ответов

- **Распределение длин запросов**:
  - Анализ длин запросов позволяет понять типичные длины входных данных и их вариативность.
  - Это важно для оценки того, как модели справляются с запросами разной сложности и объема. Например, короткие запросы могут быть менее информативными, а длинные — более сложными для обработки.
- **Распределение длин ответов**:
  - Сравнение длин ответов для `model_a` и `model_b` помогает оценить их поведение.
  - Например, если одна модель склонна генерировать более длинные ответы, это может указывать на ее "многословность" или стремление дать более подробные объяснения.
- **Взаимосвязь длины запроса и ответа**:
  - Анализ позволяет определить, приводят ли более длинные запросы к более объемным ответам.
  - Также можно выявить различия в этом аспекте между двумя моделями. Например, одна модель может быть более чувствительной к длине запроса, чем другая.

---

#### 4. Оценка эффективности моделей

- **Гистограмма побед моделей**:
  - Используется гистограмма, показывающая процент побед для каждой модели (`model_a` и `model_b`).
  - Цель: Сравнить общие показатели моделей и определить, какие из них демонстрируют лучшие результаты в соревновании.
  - Например, если одна модель выигрывает значительно чаще, это может указывать на ее превосходство в решении задачи.

## Brainstorm

Brainstorm подходов к решению задач, в частности:

* TF-IDF/BOF + SVM/LogReg
* TextCNN
* BeRT-like training
* GPT-like training
* LLM Fine Tuning

## Первые эксперименты

Проведено исследование существующих решений контеста. Самые преобладающие - LoRA или QLoRA файн тюнинг для LLM, таких как Gemma-2 или QWEN. Были произведены попытки файн тюнинга своих решений при помощи подобных подходов, но даже при достаточно маленьких архитектурах обучение занимает десятки, иногда сотни часов (на T4 или P100), а таких ресурсов у нас нет.

### LogReg и CatBoost

За основу был взят ноутбук [**"BERTenc_x_CATBOOST"**](https://www.kaggle.com/code/iitm21f1002696/bertenc-x-catboost)

1. Изучена структура и специфика данных. (EDA был выполнен на стороне @Ekaterina-Gorodkova ([EDA](report_eda.md/)))
2. Запущена первая часть решения (LogReg). По старой привычке захотелось попытаться использовать CatBoost и другие бустинги. Решил попробовать несмотря на огромное количество признаков (практически 860к). Прождав час на всех ядрах i9-12900 и забыв включить `earlystopping`, выяснил, что качество на CatBoost'е не лучше :)). Правда, не пробовал отдельно BERT'овые эмбеддинги в CatBoost'е использовать.
3. Работать гораздо проще на своих ресурсах, интернета в ноутбуках нет, поэтому модельки удобнее запускать локально. Поэтому возникает проблема портирования решений на Kaggle :(( Решаем.
